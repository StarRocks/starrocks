---
displayed_sidebar: docs
---

# ä½¿ç”¨ Arrow Flight SQL ä» StarRocks è¯»å–æ•°æ®

ä» v3.5.1 å¼€å§‹ï¼ŒStarRocks æ”¯æŒé€šè¿‡ Apache Arrow Flight SQL åè®®è¿›è¡Œè¿æ¥ã€‚

æ­¤æ–¹æ¡ˆå»ºç«‹äº†ä¸€ä¸ªä» StarRocks åˆ—å¼æ‰§è¡Œå¼•æ“åˆ°å®¢æˆ·ç«¯çš„å…¨åˆ—å¼æ•°æ®ä¼ è¾“ç®¡é“ï¼Œæ¶ˆé™¤äº†ä¼ ç»Ÿ JDBC å’Œ ODBC æ¥å£ä¸­å¸¸è§çš„é¢‘ç¹è¡Œåˆ—è½¬æ¢å’Œåºåˆ—åŒ–å¼€é”€ã€‚è¿™ä½¿å¾— StarRocks èƒ½å¤Ÿå®ç°é›¶æ‹·è´ã€ä½å»¶è¿Ÿå’Œé«˜ååé‡çš„æ•°æ®ä¼ è¾“ã€‚

## ä½¿ç”¨æ–¹æ³•

æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼Œé€šè¿‡ Arrow Flight SQL åè®®ä½¿ç”¨ Python ADBC é©±åŠ¨ç¨‹åºè¿æ¥å¹¶ä¸ StarRocks è¿›è¡Œäº¤äº’ã€‚å®Œæ•´ä»£ç ç¤ºä¾‹è¯·å‚è§[é™„å½•](#é™„å½•)ã€‚

:::note

éœ€è¦ Python 3.9 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚

:::

### æ­¥éª¤ 1. å®‰è£…åº“

ä½¿ç”¨ `pip` ä» PyPI å®‰è£… `adbc_driver_manager` å’Œ `adbc_driver_flightsql`ï¼š

```Bash
pip install adbc_driver_manager
pip install adbc_driver_flightsql
```

å°†ä»¥ä¸‹æ¨¡å—æˆ–åº“å¯¼å…¥åˆ°æ‚¨çš„ä»£ç ä¸­ï¼š

- å¿…éœ€çš„åº“ï¼š

```Python
import adbc_driver_manager
import adbc_driver_flightsql.dbapi as flight_sql
```

- å¯é€‰æ¨¡å—ä»¥æé«˜å¯ç”¨æ€§å’Œè°ƒè¯•ï¼š

```Python
import pandas as pd       # å¯é€‰ï¼šä½¿ç”¨ DataFrame æ›´å¥½åœ°æ˜¾ç¤ºç»“æœ
import traceback          # å¯é€‰ï¼šåœ¨ SQL æ‰§è¡ŒæœŸé—´æä¾›è¯¦ç»†çš„é”™è¯¯è¿½è¸ª
import time               # å¯é€‰ï¼šç”¨äºæµ‹é‡ SQL æ‰§è¡Œæ—¶é—´
```

### æ­¥éª¤ 2. è¿æ¥åˆ° StarRocks

:::note

å¦‚æœæ‚¨æƒ³åœ¨ IntelliJ IDEA ä¸­è¿è¡ŒæœåŠ¡ï¼Œå¿…é¡»åœ¨ `Run/Debug Configurations` çš„ `Build and run` ä¸­æ·»åŠ ä»¥ä¸‹é€‰é¡¹ï¼š

```Bash
--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED
```

:::

#### é…ç½® StarRocks

åœ¨é€šè¿‡ Arrow Flight SQL è¿æ¥åˆ° StarRocks ä¹‹å‰ï¼Œæ‚¨å¿…é¡»å…ˆé…ç½® FE å’Œ BE èŠ‚ç‚¹ï¼Œä»¥ç¡®ä¿ Arrow Flight SQL æœåŠ¡å·²å¯ç”¨å¹¶åœ¨æŒ‡å®šç«¯å£ä¸Šç›‘å¬ã€‚

åœ¨ FE é…ç½®æ–‡ä»¶ **fe.conf** å’Œ BE é…ç½®æ–‡ä»¶ **be.conf** ä¸­ï¼Œå°† `arrow_flight_port` è®¾ç½®ä¸ºå¯ç”¨ç«¯å£ã€‚ä¿®æ”¹é…ç½®æ–‡ä»¶åï¼Œé‡å¯ FE å’Œ BE æœåŠ¡ä»¥ä½¿ä¿®æ”¹ç”Ÿæ•ˆã€‚

ç¤ºä¾‹ï¼š

```Properties
arrow_flight_port = 9408
```

#### å»ºç«‹è¿æ¥

åœ¨å®¢æˆ·ç«¯ä¸Šï¼Œä½¿ç”¨ä»¥ä¸‹ä¿¡æ¯åˆ›å»ºä¸€ä¸ª Arrow Flight SQL å®¢æˆ·ç«¯ï¼š

- StarRocks FE çš„ä¸»æœºåœ°å€
- Arrow Flight åœ¨ StarRocks FE ä¸Šç›‘å¬çš„ç«¯å£
- æ‹¥æœ‰å¿…è¦æƒé™çš„ StarRocks ç”¨æˆ·çš„ç”¨æˆ·åå’Œå¯†ç 

ç¤ºä¾‹ï¼š

```Python
FE_HOST = "127.0.0.1"
FE_PORT = 9408

conn = flight_sql.connect(
    uri=f"grpc://{FE_HOST}:{FE_PORT}",
    db_kwargs={
        adbc_driver_manager.DatabaseOptions.USERNAME.value: "root",
        adbc_driver_manager.DatabaseOptions.PASSWORD.value: "",
    }
)
cursor = conn.cursor()
```

è¿æ¥å»ºç«‹åï¼Œæ‚¨å¯ä»¥é€šè¿‡è¿”å›çš„ Cursor æ‰§è¡Œ SQL è¯­å¥ä¸ StarRocks è¿›è¡Œäº¤äº’ã€‚

### æ­¥éª¤ 3. ï¼ˆå¯é€‰ï¼‰é¢„å®šä¹‰å·¥å…·å‡½æ•°

è¿™äº›å‡½æ•°ç”¨äºæ ¼å¼åŒ–è¾“å‡ºã€æ ‡å‡†åŒ–æ ¼å¼å’Œç®€åŒ–è°ƒè¯•ã€‚æ‚¨å¯ä»¥åœ¨ä»£ç ä¸­å¯é€‰åœ°å®šä¹‰å®ƒä»¬ä»¥è¿›è¡Œæµ‹è¯•ã€‚

```Python
# =============================================================================
# å·¥å…·å‡½æ•°ï¼Œç”¨äºæ›´å¥½çš„è¾“å‡ºæ ¼å¼åŒ–å’Œ SQL æ‰§è¡Œ
# =============================================================================

# æ‰“å°éƒ¨åˆ†æ ‡é¢˜
def print_header(title: str):
    """
    æ‰“å°éƒ¨åˆ†æ ‡é¢˜ä»¥æé«˜å¯è¯»æ€§ã€‚
    """
    print("\n" + "=" * 80)
    print(f"ğŸŸ¢ {title}")
    print("=" * 80)

# æ‰“å°æ­£åœ¨æ‰§è¡Œçš„ SQL è¯­å¥
def print_sql(sql: str):
    """
    åœ¨æ‰§è¡Œå‰æ‰“å° SQL è¯­å¥ã€‚
    """
    print(f"\nğŸŸ¡ SQL:\n{sql.strip()}")

# æ‰“å°ç»“æœ DataFrame
def print_result(df: pd.DataFrame):
    """
    ä»¥å¯è¯»æ ¼å¼æ‰“å°ç»“æœ DataFrameã€‚
    """
    if df.empty:
        print("\nğŸŸ¢ Result: (no rows returned)\n")
    else:
        print("\nğŸŸ¢ Result:\n")
        print(df.to_string(index=False))

# æ‰“å°é”™è¯¯è¿½è¸ª
def print_error(e: Exception):
    """
    å¦‚æœ SQL æ‰§è¡Œå¤±è´¥ï¼Œæ‰“å°é”™è¯¯è¿½è¸ªã€‚
    """
    print("\nğŸ”´ Error occurred:")
    traceback.print_exc()

# æ‰§è¡Œ SQL è¯­å¥å¹¶æ‰“å°ç»“æœ
def execute(sql: str):
    """
    æ‰§è¡Œ SQL è¯­å¥å¹¶æ‰“å°ç»“æœå’Œæ‰§è¡Œæ—¶é—´ã€‚
    """
    print_sql(sql)
    try:
        start = time.time()  # å¯é€‰ï¼šå¼€å§‹æ—¶é—´ç”¨äºæµ‹é‡æ‰§è¡Œæ—¶é—´
        cursor.execute(sql)
        result = cursor.fetchallarrow()  # Arrow Table
        df = result.to_pandas()  # å¯é€‰ï¼šè½¬æ¢ä¸º DataFrame ä»¥æ›´å¥½åœ°æ˜¾ç¤º
        print_result(df)
        print(f"\nâ±ï¸  Execution time: {time.time() - start:.3f} seconds")
    except Exception as e:
        print_error(e)
```

### æ­¥éª¤ 4. ä¸ StarRocks äº¤äº’

æœ¬èŠ‚å°†æŒ‡å¯¼æ‚¨å®Œæˆä¸€äº›åŸºæœ¬æ“ä½œï¼Œä¾‹å¦‚åˆ›å»ºè¡¨ã€å¯¼å…¥æ•°æ®ã€æ£€æŸ¥è¡¨ç»“æ„ã€è®¾ç½®å˜é‡å’Œè¿è¡ŒæŸ¥è¯¢ã€‚

:::note

ä¸‹é¢åˆ—å‡ºçš„è¾“å‡ºç¤ºä¾‹æ˜¯åŸºäºå‰è¿°æ­¥éª¤ä¸­æè¿°çš„å¯é€‰æ¨¡å—å’Œå·¥å…·å‡½æ•°å®ç°çš„ã€‚

:::

1. åˆ›å»ºä¸€ä¸ªæ•°æ®åº“å’Œä¸€ä¸ªå°†å¯¼å…¥æ•°æ®çš„è¡¨ï¼Œå¹¶æ£€æŸ¥è¡¨ç»“æ„ã€‚

   ```Python
   # Step 1: Drop and create database
   print_header("Step 1: Drop and Create Database")
   execute("DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;")
   execute("SHOW DATABASES;")
   execute("CREATE DATABASE sr_arrow_flight_sql;")
   execute("SHOW DATABASES;")
   execute("USE sr_arrow_flight_sql;")
   
   # Step 2: Create table
   print_header("Step 2: Create Table")
   execute("""
   CREATE TABLE sr_arrow_flight_sql_test
   (
       k0 INT,
       k1 DOUBLE,
       k2 VARCHAR(32) NULL DEFAULT "" COMMENT "",
       k3 DECIMAL(27,9) DEFAULT "0",
       k4 BIGINT NULL DEFAULT '10',
       k5 DATE
   )
   DISTRIBUTED BY HASH(k5) BUCKETS 5
   PROPERTIES("replication_num" = "1");
   """)
   execute("SHOW CREATE TABLE sr_arrow_flight_sql_test;")
   ```

   ç¤ºä¾‹è¾“å‡ºï¼š

   ```SQL
   ================================================================================
   ğŸŸ¢ Step 1: Drop and Create Database
   ================================================================================
   
   ğŸŸ¡ SQL:
   DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;
   /Users/starrocks/test/venv/lib/python3.9/site-packages/adbc_driver_manager/dbapi.py:307: Warning: Cannot disable autocommit; conn will not be DB-API 2.0 compliant
     warnings.warn(
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.025 seconds
   
   ğŸŸ¡ SQL:
   SHOW DATABASES;
   
   ğŸŸ¢ Result:
   
             Database
         _statistics_
                 hits
   information_schema
                  sys
   
   â±ï¸  Execution time: 0.014 seconds
   
   ğŸŸ¡ SQL:
   CREATE DATABASE sr_arrow_flight_sql;
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.012 seconds
   
   ğŸŸ¡ SQL:
   SHOW DATABASES;
   
   ğŸŸ¢ Result:
   
              Database
          _statistics_
                  hits
    information_schema
   sr_arrow_flight_sql
                   sys
   
   â±ï¸  Execution time: 0.005 seconds
   
   ğŸŸ¡ SQL:
   USE sr_arrow_flight_sql;
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.006 seconds
   
   ================================================================================
   ğŸŸ¢ Step 2: Create Table
   ================================================================================
   
   ğŸŸ¡ SQL:
   CREATE TABLE sr_arrow_flight_sql_test
   (
       k0 INT,
       k1 DOUBLE,
       k2 VARCHAR(32) NULL DEFAULT "" COMMENT "",
       k3 DECIMAL(27,9) DEFAULT "0",
       k4 BIGINT NULL DEFAULT '10',
       k5 DATE
   )
   DISTRIBUTED BY HASH(k5) BUCKETS 5
   PROPERTIES("replication_num" = "1");
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.021 seconds
   
   ğŸŸ¡ SQL:
   SHOW CREATE TABLE sr_arrow_flight_sql_test;
   
   ğŸŸ¢ Result:
   
                      Table                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Create Table
   sr_arrow_flight_sql_test CREATE TABLE `sr_arrow_flight_sql_test` (\n  `k0` int(11) NULL COMMENT "",\n  `k1` double NULL COMMENT "",\n  `k2` varchar(32) NULL DEFAULT "" COMMENT "",\n  `k3` decimal(27, 9) NULL DEFAULT "0" COMMENT "",\n  `k4` bigint(20) NULL DEFAULT "10" COMMENT "",\n  `k5` date NULL COMMENT ""\n) ENGINE=OLAP \nDUPLICATE KEY(`k0`)\nDISTRIBUTED BY HASH(`k5`) BUCKETS 5 \nPROPERTIES (\n"compression" = "LZ4",\n"fast_schema_evolution" = "true",\n"replicated_storage" = "true",\n"replication_num" = "1"\n);
   
   â±ï¸  Execution time: 0.005 seconds
   ```
2. æ’å…¥æ•°æ®ï¼Œè¿è¡Œä¸€äº›æŸ¥è¯¢ï¼Œå¹¶è®¾ç½®å˜é‡ã€‚

   ```Python
   # Step 3: Insert data
   print_header("Step 3: Insert Data")
   execute("""
   INSERT INTO sr_arrow_flight_sql_test VALUES
       (0, 0.1, "ID", 0.0001, 1111111111, '2025-04-21'),
       (1, 0.20, "ID_1", 1.00000001, 0, '2025-04-21'),
       (2, 3.4, "ID_1", 3.1, 123456, '2025-04-22'),
       (3, 4, "ID", 4, 4, '2025-04-22'),
       (4, 122345.54321, "ID", 122345.54321, 5, '2025-04-22');
   """)
   
   # Step 4: Query data
   print_header("Step 4: Query Data")
   execute("SELECT * FROM sr_arrow_flight_sql_test ORDER BY k0;")
   
   # Step 5: Session variables
   print_header("Step 5: Session Variables")
   execute("SHOW VARIABLES LIKE '%query_mem_limit%';")
   execute("SET query_mem_limit = 2147483648;")
   execute("SHOW VARIABLES LIKE '%query_mem_limit%';")
   
   # Step 6: Aggregation query
   print_header("Step 6: Aggregation Query")
   execute("""
   SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
   FROM sr_arrow_flight_sql_test
   GROUP BY k5
   ORDER BY k5;
   """)
   ```

   ç¤ºä¾‹è¾“å‡ºï¼š

   ```SQL
   ================================================================================
   ğŸŸ¢ Step 3: Insert Data
   ================================================================================
   
   ğŸŸ¡ SQL:
   INSERT INTO sr_arrow_flight_sql_test VALUES
       (0, 0.1, "ID", 0.0001, 1111111111, '2025-04-21'),
       (1, 0.20, "ID_1", 1.00000001, 0, '2025-04-21'),
       (2, 3.4, "ID_1", 3.1, 123456, '2025-04-22'),
       (3, 4, "ID", 4, 4, '2025-04-22'),
       (4, 122345.54321, "ID", 122345.54321, 5, '2025-04-22');
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.149 seconds
   
   ================================================================================
   ğŸŸ¢ Step 4: Query Data
   ================================================================================
   
   ğŸŸ¡ SQL:
   SELECT * FROM sr_arrow_flight_sql_test ORDER BY k0;
   
   ğŸŸ¢ Result:
                                                             
   0      0.10000   ID      0.000100000 1111111111 2025-04-21
   1      0.20000 ID_1      1.000000010          0 2025-04-21
   2      3.40000 ID_1      3.100000000     123456 2025-04-22
   3      4.00000   ID      4.000000000          4 2025-04-22
   4 122345.54321   ID 122345.543210000          5 2025-04-22
   
   â±ï¸  Execution time: 0.019 seconds
   
   ================================================================================
   ğŸŸ¢ Step 5: Session Variables
   ================================================================================
   
   ğŸŸ¡ SQL:
   SHOW VARIABLES LIKE '%query_mem_limit%';
   
   ğŸŸ¢ Result:
   
     Variable_name Value
   query_mem_limit     0
   
   â±ï¸  Execution time: 0.005 seconds
   
   ğŸŸ¡ SQL:
   SET query_mem_limit = 2147483648;
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.007 seconds
   
   ğŸŸ¡ SQL:
   SHOW VARIABLES LIKE '%query_mem_limit%';
   
   ğŸŸ¢ Result:
   
     Variable_name      Value
   query_mem_limit 2147483648
   
   â±ï¸  Execution time: 0.005 seconds
   
   ================================================================================
   ğŸŸ¢ Step 6: Aggregation Query
   ================================================================================
   
   ğŸŸ¡ SQL:
   SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
   FROM sr_arrow_flight_sql_test
   GROUP BY k5
   ORDER BY k5;
   
   ğŸŸ¢ Result:
                                               
   2025-04-21      0.30000 2     0.500050005000
   2025-04-22 122352.94321 3 40784.214403333333
   
   â±ï¸  Execution time: 0.014 second
   ```

### æ­¥éª¤ 5. å…³é—­è¿æ¥

åœ¨ä»£ç ä¸­åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ä»¥å…³é—­è¿æ¥ã€‚

```Python
# Step 7: Close
print_header("Step 7: Close Connection")
cursor.close()
conn.close()
print("âœ… Test completed successfully.")
```

ç¤ºä¾‹è¾“å‡ºï¼š

```Python
================================================================================
ğŸŸ¢ Step 7: Close Connection
================================================================================
âœ… Test completed successfully.

Process finished with exit code 0
```

## å¤§è§„æ¨¡æ•°æ®ä¼ è¾“çš„ç”¨ä¾‹

### Python

é€šè¿‡ ADBC é©±åŠ¨ç¨‹åºåœ¨ Python ä¸­è¿æ¥åˆ°æ”¯æŒ Arrow Flight SQL çš„ StarRocks åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å„ç§ ADBC API å°† Clickbench æ•°æ®é›†ä» StarRocks åŠ è½½åˆ° Python ä¸­ã€‚

ä»£ç ç¤ºä¾‹ï¼š

```Python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import adbc_driver_manager
import adbc_driver_flightsql.dbapi as flight_sql
from datetime import datetime

# ----------------------------------------
# StarRocks Flight SQL Connection Settings
# ----------------------------------------
# Replace the URI and credentials as needed
my_uri = "grpc://127.0.0.1:9408"  # Default Flight SQL port for StarRocks
my_db_kwargs = {
    adbc_driver_manager.DatabaseOptions.USERNAME.value: "root",
    adbc_driver_manager.DatabaseOptions.PASSWORD.value: "",
}

# ----------------------------------------
# SQL Query (ClickBench: hits table)
# ----------------------------------------
# Replace with the actual table and dataset as needed
sql = "SELECT * FROM clickbench.hits LIMIT 1000000;"  # Read 1 million rows

# ----------------------------------------
# Method 1: fetchallarrow + to_pandas
# ----------------------------------------
def test_fetchallarrow():
    conn = flight_sql.connect(uri=my_uri, db_kwargs=my_db_kwargs)
    cursor = conn.cursor()
    start = datetime.now()
    cursor.execute(sql)
    arrow_table = cursor.fetchallarrow()
    df = arrow_table.to_pandas()
    duration = datetime.now() - start

    print("\n[Method 1] fetchallarrow + to_pandas")
    print(f"Time taken: {duration}, Arrow table size: {arrow_table.nbytes / 1024 / 1024:.2f} MB, Rows: {len(df)}")
    print(df.info(memory_usage='deep'))

# ----------------------------------------
# Method 2: fetch_df (recommended)
# ----------------------------------------
def test_fetch_df():
    conn = flight_sql.connect(uri=my_uri, db_kwargs=my_db_kwargs)
    cursor = conn.cursor()
    start = datetime.now()
    cursor.execute(sql)
    df = cursor.fetch_df()
    duration = datetime.now() - start

    print("\n[Method 2] fetch_df (recommended)")
    print(f"Time taken: {duration}, Rows: {len(df)}")
    print(df.info(memory_usage='deep'))

# ----------------------------------------
# Method 3: adbc_execute_partitions (for parallel read)
# ----------------------------------------
def test_execute_partitions():
    conn = flight_sql.connect(uri=my_uri, db_kwargs=my_db_kwargs)
    cursor = conn.cursor()
    start = datetime.now()
    partitions, schema = cursor.adbc_execute_partitions(sql)

    # Read the first partition (for demo)
    cursor.adbc_read_partition(partitions[0])
    arrow_table = cursor.fetchallarrow()
    df = arrow_table.to_pandas()
    duration = datetime.now() - start

    print("\n[Method 3] adbc_execute_partitions (parallel read)")
    print(f"Time taken: {duration}, Partitions: {len(partitions)}, Rows: {len(df)}")
    print(df.info(memory_usage='deep'))

# ----------------------------------------
# Run All Tests
# ----------------------------------------
if __name__ == "__main__":
    test_fetchallarrow()
    test_fetch_df()
    test_execute_partitions()
```

ç»“æœè¡¨æ˜ï¼Œä» StarRocks åŠ è½½ 100 ä¸‡è¡Œ Clickbench æ•°æ®é›†ï¼ˆ105 åˆ—ï¼Œ780 MBï¼‰ä»…ç”¨äº† 3 ç§’ã€‚

```Python
[Method 1] fetchallarrow + to_pandas
Time taken: 0:00:03.219575, Arrow table size: 717.42 MB, Rows: 1000000
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000000 entries, 0 to 999999
Columns: 105 entries, CounterID to CLID
dtypes: int16(48), int32(19), int64(6), object(32)
memory usage: 2.4 GB

[Method 2] fetch_df (recommended)
Time taken: 0:00:02.358840, Rows: 1000000
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000000 entries, 0 to 999999
Columns: 105 entries, CounterID to CLID
dtypes: int16(48), int32(19), int64(6), object(32)
memory usage: 2.4 GB

[Method 3] adbc_execute_partitions (parallel read)
Time taken: 0:00:02.231144, Partitions: 1, Rows: 1000000
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000000 entries, 0 to 999999
Columns: 105 entries, CounterID to CLID
dtypes: int16(48), int32(19), int64(6), object(32)
memory usage: 2.4 GB
```

### Arrow Flight SQL JDBC é©±åŠ¨ç¨‹åº

Arrow Flight SQL åè®®æä¾›äº†ä¸€ä¸ªå¼€æºçš„ JDBC é©±åŠ¨ç¨‹åºï¼Œä¸æ ‡å‡† JDBC æ¥å£å…¼å®¹ã€‚æ‚¨å¯ä»¥è½»æ¾åœ°å°†å…¶é›†æˆåˆ°å„ç§ BI å·¥å…·ï¼ˆå¦‚ Tableauã€Power BIã€DBeaver ç­‰ï¼‰ä¸­ï¼Œä»¥è®¿é—® StarRocks æ•°æ®åº“ï¼Œå°±åƒä½¿ç”¨ä¼ ç»Ÿ JDBC é©±åŠ¨ç¨‹åºä¸€æ ·ã€‚æ­¤é©±åŠ¨ç¨‹åºçš„ä¸€ä¸ªæ˜¾è‘—ä¼˜åŠ¿æ˜¯å…¶åŸºäº Apache Arrow çš„é«˜é€Ÿæ•°æ®ä¼ è¾“æ”¯æŒï¼Œå¤§å¤§æé«˜äº†æŸ¥è¯¢å’Œæ•°æ®ä¼ è¾“çš„æ•ˆç‡ã€‚ä½¿ç”¨æ–¹æ³•å‡ ä¹ä¸ä¼ ç»Ÿçš„ MySQL JDBC é©±åŠ¨ç¨‹åºç›¸åŒã€‚æ‚¨åªéœ€åœ¨è¿æ¥ URL ä¸­å°† `jdbc:mysql` æ›¿æ¢ä¸º `jdbc:arrow-flight-sql` å³å¯æ— ç¼åˆ‡æ¢ã€‚æŸ¥è¯¢ç»“æœä»ç„¶ä»¥æ ‡å‡† `ResultSet` æ ¼å¼è¿”å›ï¼Œç¡®ä¿ä¸ç°æœ‰ JDBC å¤„ç†é€»è¾‘çš„å…¼å®¹æ€§ã€‚

:::note

å¦‚æœæ‚¨æƒ³åœ¨ IntelliJ IDEA ä¸­è¿›è¡Œè°ƒè¯•ï¼Œå¿…é¡»åœ¨ `Run/Debug Configurations` çš„ `Build and run` ä¸­æ·»åŠ ä»¥ä¸‹é€‰é¡¹ï¼š

```Bash
--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED
```

:::

<details>

  <summary>POM ä¾èµ–</summary>

```XML
<properties>
    <adbc.version>0.15.0</adbc.version>
</properties>

<dependencies>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-jdbc</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-core</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-manager</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-flight-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
</dependencies>
```

</details>

ä»£ç ç¤ºä¾‹ï¼š

```Java
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;

/**
 * Integration test for Arrow Flight SQL JDBC driver with StarRocks.
 *
 * This test covers:
 *  - Basic DDL and DML operations
 *  - Query execution and result validation
 *  - Error handling for invalid SQL
 *  - Query cancellation (simulated with a long-running query)
 */
public class ArrowFlightSqlIntegrationTest {

    private static final String JDBC_URL = "jdbc:arrow-flight-sql://127.0.0.1:9408"
            + "?useEncryption=false"
            + "&useServerPrepStmts=false"
            + "&useSSL=false"
            + "&useArrowFlightSql=true";

    private static final String USER = "root";
    private static final String PASSWORD = "";

    private static int testCaseNum = 1;

    public static void main(String[] args) {
        try {
            // Load Arrow Flight SQL JDBC driver
            Class.forName("org.apache.arrow.driver.jdbc.ArrowFlightJdbcDriver");

            try (Connection conn = DriverManager.getConnection(JDBC_URL, USER, PASSWORD);
                    Statement stmt = conn.createStatement()) {

                // Basic DDL and DML operations
                testUpdate(stmt, "DROP DATABASE IF EXISTS arrow_demo FORCE;");
                testQuery(stmt, "SHOW PROCESSLIST;");
                testUpdate(stmt, "CREATE DATABASE arrow_demo;");
                testQuery(stmt, "SHOW DATABASES;");
                testUpdate(stmt, "USE arrow_demo;");
                testUpdate(stmt, "CREATE TABLE test (id INT, name STRING) ENGINE=OLAP PRIMARY KEY (id) " +
                        "DISTRIBUTED BY HASH(id) BUCKETS 1 " +
                        "PROPERTIES ('replication_num' = '1');");
                testUpdate(stmt, "INSERT INTO test VALUES (1, 'Alice'), (2, 'Bob');");
                testUpdate(stmt, "INSERT INTO test VALUES (1, 'Alice'), (2, 'Bob');");
                testUpdate(stmt, "INSERT INTO test VALUES (3, 'Zac'), (4, 'Tom');");
                testQuery(stmt, "SELECT * FROM test;");
                testUpdate(stmt, "UPDATE test SET name = 'Charlie' WHERE id = 1;");
                testQuery(stmt, "SELECT * FROM arrow_demo.test;");
                testUpdate(stmt, "DELETE FROM test WHERE id = 2;");
                testUpdate(stmt, "ALTER TABLE test ADD COLUMN age INT;");
                testUpdate(stmt, "ALTER TABLE test MODIFY COLUMN name STRING;");
                testQuery(stmt, "SHOW CREATE TABLE test;");
                testUpdate(stmt, "INSERT INTO test (id, name, age) VALUES (5, 'Eve', 30);");
                testQuery(stmt, "SELECT * FROM test WHERE id = 5;");
                testQuery(stmt, "SELECT * FROM test;");
                testQuery(stmt, "SHOW CREATE TABLE test;");

                testUpdate(stmt, "CREATE TABLE test2 (id INT, age INT) ENGINE=OLAP PRIMARY KEY (id) " +
                        "DISTRIBUTED BY HASH(id) BUCKETS 1 " +
                        "PROPERTIES ('replication_num' = '1');");
                testUpdate(stmt, "INSERT INTO test2 VALUES (1, 18), (2, 20);");
                testQuery(stmt, "SELECT arrow_demo.test.id, arrow_demo.test.name, arrow_demo.test2.age FROM arrow_demo.test " +
                        "LEFT JOIN arrow_demo.test2 ON arrow_demo.test.id = arrow_demo.test2.id;");

                testQuery(stmt, "SELECT * FROM (SELECT id, name FROM test) AS sub WHERE id = 1;");
                testUpdate(stmt, "SET time_zone = '+08:00';");

                // Error handling: query on non-existent table
                try {
                    testQuery(stmt, "SELECT * FROM not_exist_table;");
                } catch (Exception e) {
                    System.out.println("âœ… Expected error (table not exist): " + e.getMessage());
                }

                // Error handling: SQL syntax error
                try {
                    testQuery(stmt, "SELECT * FROM arrow_demo.test WHERE id = ;");
                } catch (Exception e) {
                    System.out.println("âœ… Expected error (syntax error): " + e.getMessage());
                }

                // Query cancellation test
                try {
                    System.out.println("Test Case: " + testCaseNum);
                    System.out.println("â–¶ Executing long-running query (SELECT SLEEP(10)) and canceling after 1s");

                    try (Statement longStmt = conn.createStatement()) {
                        Thread cancelThread = new Thread(() -> {
                            try {
                                Thread.sleep(1);
                                try {
                                    longStmt.cancel();
                                    System.out.println("âœ… Query cancel() called.");
                                } catch (SQLException e) {
                                    System.out.println("âš ï¸  Statement cancel() failed: " + e.getMessage());
                                }
                            } catch (InterruptedException e) {
                                e.printStackTrace();
                            }
                        });
                        cancelThread.start();

                        testQuery(longStmt, "SELECT * FROM information_schema.columns;");
                    }
                } catch (Exception e) {
                    System.out.println("âœ… Expected error (query cancelled): " + e.getMessage());
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        }

        System.out.println("âœ… SQL syntax coverage testing completed");
    }

    /**
     * Executes a query and prints the result to the console.
     */
    private static void testQuery(Statement stmt, String sql) throws Exception {
        System.out.println("Test Case: " + testCaseNum);
        System.out.println("â–¶ Executing query: " + sql);
        try (ResultSet rs = stmt.executeQuery(sql)) {
            System.out.println("Result:");
            int columnCount = rs.getMetaData().getColumnCount();
            while (rs.next()) {
                for (int i = 1; i <= columnCount; i++) {
                    System.out.print(rs.getString(i) + "\t");
                }
                System.out.println();
            }
        }
        testCaseNum++;
        System.out.println();
    }

    /**
     * Executes an update (DDL or DML) and prints the result to the console.
     */
    private static void testUpdate(Statement stmt, String sql) throws Exception {
        System.out.println("Test Case: " + testCaseNum);
        System.out.println("â–¶ Executing update: " + sql);
        stmt.executeUpdate(sql);
        System.out.println("Result: âœ… Success");
        testCaseNum++;
        System.out.println();
    }
}
```

æ‰§è¡Œç»“æœï¼š

```Bash
Test Case: 1
â–¶ Executing update: DROP DATABASE IF EXISTS arrow_demo FORCE;
Result: âœ… Success

Test Case: 2
â–¶ Executing query: SHOW PROCESSLIST;
Result:
192.168.124.17_9010_1745287990251        16777217        root        127.0.0.1:58950        hits        Sleep        2025-04-22 10:26:43        4745        EOF        select count(*) from hits        false        
192.168.124.17_9010_1745287990251        16777218        root                sr_arrow_flight_sql        Sleep        2025-04-22 10:45:21        11221        ERR        show create table arrow_flight_sql_test;        false        
192.168.124.17_9010_1745287990251        16777219        root                sr_arrow_flight_sql        Sleep        2025-04-22 10:45:56        11186        EOF        show create table sr_arrow_flight_sql_test;        false        
192.168.124.17_9010_1745287990251        16777220        root                sr_arrow_flight_sql        Sleep        2025-04-22 10:50:06        10935        ERR        
SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
FROM sr_arrow_flight_sql_t        false        
192.168.124.17_9010_1745287990251        16777221        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:23:11        8951        EOF        SHOW CREATE TABLE sr_arrow_flight_sql_test;        false        
192.168.124.17_9010_1745287990251        16777222        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:24:08        8894        EOF        SHOW CREATE TABLE sr_arrow_flight_sql_test;        false        
192.168.124.17_9010_1745287990251        16777223        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:31:06        8476        OK        
SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
FROM sr_arrow_flight_sql_t        false        
192.168.124.17_9010_1745287990251        16777224        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:31:20        8462        ERR        
SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
FROM sr_arrow_flight_sql_t        false        
192.168.124.17_9010_1745287990251        16777225        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:37:47        8075        ERR        INSERT INTO arrow_flight_sql_test VALUES
        (0, 0.1, "ID", 0.0001, 9999999999, '2023-10-21'),
         false        
192.168.124.17_9010_1745287990251        16777226        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:38:10        8052        ERR        select k5, sum(k1), count(1), avg(k3) from arrow_flight_sql_test group by k5;        false        
192.168.124.17_9010_1745287990251        16777227        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:42:43        7779        ERR        
SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
FROM sr_arrow_flight_sql_t        false        
192.168.124.17_9010_1745287990251        16777228        root                sr_arrow_flight_sql        Sleep        2025-04-22 11:46:47        7535        ERR        
SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
FROM sr_arrow_flight_sql_t        false        
192.168.124.17_9010_1745287990251        16777229        root                        Sleep        2025-04-22 12:34:46        4656        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777230        root                        Sleep        2025-04-22 12:34:54        4648        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777231        root                        Sleep        2025-04-22 12:34:59        4643        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777232        root                        Sleep        2025-04-22 12:37:11        4511        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777233        root                        Sleep        2025-04-22 12:37:18        4505        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777234        root                        Sleep        2025-04-22 12:37:23        4499        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777235        root                        Sleep        2025-04-22 12:37:58        4464        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777236        root                        Sleep        2025-04-22 12:38:05        4457        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777237        root                        Sleep        2025-04-22 12:38:11        4451        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777238        root                        Sleep        2025-04-22 12:40:38        4304        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777239        root                        Sleep        2025-04-22 12:40:44        4298        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777240        root                        Sleep        2025-04-22 12:40:50        4292        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777241        root                        Sleep        2025-04-22 12:41:23        4259        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777242        root                        Sleep        2025-04-22 12:41:30        4252        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777243        root                        Sleep        2025-04-22 12:41:36        4246        ERR        SELECT * FROM hits.hits LIMIT 1000000;        false        
192.168.124.17_9010_1745287990251        16777244        root                        Query        2025-04-22 13:52:22        0        OK        SHOW PROCESSLIST;        false        

Test Case: 3
â–¶ Executing update: CREATE DATABASE arrow_demo;
Result: âœ… Success

Test Case: 4
â–¶ Executing query: SHOW DATABASES;
Result:
_statistics_        
arrow_demo        
arrow_flight_sql        
hits        
information_schema        
sr_arrow_flight_sql        
sys        

Test Case: 5
â–¶ Executing update: USE arrow_demo;
Result: âœ… Success

Test Case: 6
â–¶ Executing update: CREATE TABLE test (id INT, name STRING) ENGINE=OLAP PRIMARY KEY (id) DISTRIBUTED BY HASH(id) BUCKETS 1 PROPERTIES ('replication_num' = '1');
Result: âœ… Success

Test Case: 7
â–¶ Executing update: INSERT INTO test VALUES (1, 'Alice'), (2, 'Bob');
Result: âœ… Success

Test Case: 8
â–¶ Executing update: INSERT INTO test VALUES (1, 'Alice'), (2, 'Bob');
Result: âœ… Success

Test Case: 9
â–¶ Executing update: INSERT INTO test VALUES (3, 'Zac'), (4, 'Tom');
Result: âœ… Success

Test Case: 10
â–¶ Executing query: SELECT * FROM test;
Result:
1        Alice        
2        Bob        
3        Zac        
4        Tom        

Test Case: 11
â–¶ Executing update: UPDATE test SET name = 'Charlie' WHERE id = 1;
Result: âœ… Success

Test Case: 12
â–¶ Executing query: SELECT * FROM arrow_demo.test;
Result:
2        Bob        
3        Zac        
4        Tom        
1        Charlie        

Test Case: 13
â–¶ Executing update: DELETE FROM test WHERE id = 2;
Result: âœ… Success

Test Case: 14
â–¶ Executing update: ALTER TABLE test ADD COLUMN age INT;
Result: âœ… Success

Test Case: 15
â–¶ Executing update: ALTER TABLE test MODIFY COLUMN name STRING;
Result: âœ… Success

Test Case: 16
â–¶ Executing query: SHOW CREATE TABLE test;
Result:
test        CREATE TABLE `test` (
  `id` int(11) NOT NULL COMMENT "",
  `name` varchar(65533) NULL COMMENT "",
  `age` int(11) NULL COMMENT ""
) ENGINE=OLAP 
PRIMARY KEY(`id`)
DISTRIBUTED BY HASH(`id`) BUCKETS 1 
PROPERTIES (
"compression" = "LZ4",
"enable_persistent_index" = "true",
"fast_schema_evolution" = "true",
"replicated_storage" = "true",
"replication_num" = "1"
);        

Test Case: 17
â–¶ Executing update: INSERT INTO test (id, name, age) VALUES (5, 'Eve', 30);
Result: âœ… Success

Test Case: 18
â–¶ Executing query: SELECT * FROM test WHERE id = 5;
Result:
5        Eve        30        

Test Case: 19
â–¶ Executing query: SELECT * FROM test;
Result:
3        Zac        null        
4        Tom        null        
1        Charlie        null        
5        Eve        30        

Test Case: 20
â–¶ Executing query: SHOW CREATE TABLE test;
Result:
test        CREATE TABLE `test` (
  `id` int(11) NOT NULL COMMENT "",
  `name` varchar(65533) NULL COMMENT "",
  `age` int(11) NULL COMMENT ""
) ENGINE=OLAP 
PRIMARY KEY(`id`)
DISTRIBUTED BY HASH(`id`) BUCKETS 1 
PROPERTIES (
"compression" = "LZ4",
"enable_persistent_index" = "true",
"fast_schema_evolution" = "true",
"replicated_storage" = "true",
"replication_num" = "1"
);        

Test Case: 21
â–¶ Executing update: CREATE TABLE test2 (id INT, age INT) ENGINE=OLAP PRIMARY KEY (id) DISTRIBUTED BY HASH(id) BUCKETS 1 PROPERTIES ('replication_num' = '1');
Result: âœ… Success

Test Case: 22
â–¶ Executing update: INSERT INTO test2 VALUES (1, 18), (2, 20);
Result: âœ… Success

Test Case: 23
â–¶ Executing query: SELECT arrow_demo.test.id, arrow_demo.test.name, arrow_demo.test2.age FROM arrow_demo.test LEFT JOIN arrow_demo.test2 ON arrow_demo.test.id = arrow_demo.test2.id;
Result:
4        Tom        null        
3        Zac        null        
5        Eve        null        
1        Charlie        18        

Test Case: 24
â–¶ Executing query: SELECT * FROM (SELECT id, name FROM test) AS sub WHERE id = 1;
Result:
1        Charlie        

Test Case: 25
â–¶ Executing update: SET time_zone = '+08:00';
Result: âœ… Success

Test Case: 26
â–¶ Executing query: SELECT * FROM not_exist_table;
âœ… Expected error (table not exist): Error while executing SQL "SELECT * FROM not_exist_table;": failed to process query [queryID=f70a03a5-1f3d-11f0-92e7-f29d1152bb04] [error=Getting analyzing error. Detail message: Unknown table 'arrow_demo.not_exist_table'.]
Test Case: 26
â–¶ Executing query: SELECT * FROM arrow_demo.test WHERE id = ;
âœ… Expected error (syntax error): Error while executing SQL "SELECT * FROM arrow_demo.test WHERE id = ;": com.starrocks.sql.parser.ParsingException: Getting syntax error at line 1, column 39. Detail message: Unexpected input '=', the most similar input is {<EOF>, ';'}.
Test Case: 26
â–¶ Executing long-running query (SELECT SLEEP(10)) and canceling after 1s
Test Case: 26
â–¶ Executing query: SELECT * FROM information_schema.columns;
âœ… Query cancel() called.
Result:
âœ… Expected error (query cancelled): Statement canceled
âœ… SQL syntax coverage testing completed
```

### Java ADBC é©±åŠ¨ç¨‹åº

Arrow Flight SQL åè®®æä¾›äº†ä¸€ä¸ªå¼€æºçš„ JDBC é©±åŠ¨ç¨‹åºï¼Œä¸æ ‡å‡† JDBC æ¥å£å…¼å®¹ã€‚æ‚¨å¯ä»¥è½»æ¾åœ°å°†å…¶é›†æˆåˆ°å„ç§ BI å·¥å…·ï¼ˆå¦‚ Tableauã€Power BIã€DBeaver ç­‰ï¼‰ä¸­ï¼Œä»¥è®¿é—® StarRocks æ•°æ®åº“ï¼Œå°±åƒä½¿ç”¨ä¼ ç»Ÿ JDBC é©±åŠ¨ç¨‹åºä¸€æ ·ã€‚æ­¤é©±åŠ¨ç¨‹åºçš„ä¸€ä¸ªæ˜¾è‘—ä¼˜åŠ¿æ˜¯å…¶åŸºäº Apache Arrow çš„é«˜é€Ÿæ•°æ®ä¼ è¾“æ”¯æŒï¼Œå¤§å¤§æé«˜äº†æŸ¥è¯¢å’Œæ•°æ®ä¼ è¾“çš„æ•ˆç‡ã€‚ä½¿ç”¨æ–¹æ³•å‡ ä¹ä¸ä¼ ç»Ÿçš„ MySQL JDBC é©±åŠ¨ç¨‹åºç›¸åŒã€‚æ‚¨åªéœ€åœ¨è¿æ¥ URL ä¸­å°† `jdbc:mysql` æ›¿æ¢ä¸º `jdbc:arrow-flight-sql` å³å¯æ— ç¼åˆ‡æ¢ã€‚æŸ¥è¯¢ç»“æœä»ç„¶ä»¥æ ‡å‡† `ResultSet` æ ¼å¼è¿”å›ï¼Œç¡®ä¿ä¸ç°æœ‰ JDBC å¤„ç†é€»è¾‘çš„å…¼å®¹æ€§ã€‚

:::note

å¦‚æœæ‚¨æƒ³åœ¨ IntelliJ IDEA ä¸­è¿›è¡Œè°ƒè¯•ï¼Œå¿…é¡»åœ¨ `Run/Debug Configurations` çš„ `Build and run` ä¸­æ·»åŠ ä»¥ä¸‹é€‰é¡¹ï¼š

```Bash
--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED
```

:::

<details>

  <summary>POM ä¾èµ–</summary>

```XML
<properties>
    <adbc.version>0.15.0</adbc.version>
</properties>

<dependencies>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-jdbc</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-core</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-manager</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-flight-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
</dependencies>
```

</details>

ä¸ Python ä¸­çš„ç”¨æ³•ç±»ä¼¼ï¼Œæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥åœ¨ Java ä¸­åˆ›å»º ADBC å®¢æˆ·ç«¯ä»¥ä» StarRocks è¯»å–æ•°æ®ã€‚

åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæ‚¨é¦–å…ˆéœ€è¦è·å– FlightInfoï¼Œç„¶åè¿æ¥åˆ°æ¯ä¸ª Endpoint ä»¥è·å–æ•°æ®ã€‚

ä»£ç ç¤ºä¾‹ï¼š

```Java
public static void main(String[] args) throws Exception {
    try (BufferAllocator allocator = new RootAllocator()) {
        FlightSqlDriver driver = new FlightSqlDriver(allocator);

        Map<String, Object> parameters = new HashMap<>();
        String host = "localhost";
        int port = 9408;
        String uri = Location.forGrpcInsecure(host, port).getUri().toString();

        AdbcDriver.PARAM_URI.set(parameters, uri);
        AdbcDriver.PARAM_USERNAME.set(parameters, "root");
        AdbcDriver.PARAM_PASSWORD.set(parameters, "");

        try (AdbcDatabase database = driver.open(parameters);
                AdbcConnection connection = database.connect();
                AdbcStatement statement = connection.createStatement()) {

            statement.setSqlQuery("SHOW DATABASES;");

            try (AdbcStatement.QueryResult result = statement.executeQuery();
                    ArrowReader reader = result.getReader()) {

                int batchCount = 0;
                while (reader.loadNextBatch()) {
                    batchCount++;
                    VectorSchemaRoot root = reader.getVectorSchemaRoot();
                    System.out.println("Batch " + batchCount + ":");
                    System.out.println(root.contentToTSVString());
                }

                System.out.println("Total batches: " + batchCount);
            }
        }
    }
}
```

### Spark

ç›®å‰ï¼Œå®˜æ–¹çš„ Arrow Flight é¡¹ç›®å°šæ— è®¡åˆ’æ”¯æŒ Spark æˆ– Flinkã€‚æœªæ¥å°†é€æ­¥å¢åŠ æ”¯æŒï¼Œä»¥ä¾¿ [starrocks-spark-connector](https://github.com/qwshen/spark-flight-connector) èƒ½å¤Ÿé€šè¿‡ Arrow Flight SQL è®¿é—® StarRocksï¼Œé¢„è®¡è¯»æ€§èƒ½å°†æå‡æ•°å€ã€‚

åœ¨ä½¿ç”¨ Spark è®¿é—® StarRocks æ—¶ï¼Œé™¤äº†ä¼ ç»Ÿçš„ JDBC æˆ– Java å®¢æˆ·ç«¯æ–¹æ³•å¤–ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨å¼€æºçš„ Spark-Flight-Connector ç»„ä»¶ï¼Œç›´æ¥ä» StarRocks Flight SQL Server è¯»å–å’Œå†™å…¥æ•°æ®ä½œä¸º Spark DataSourceã€‚è¿™ç§åŸºäº Apache Arrow Flight åè®®çš„æ–¹æ³•å…·æœ‰ä»¥ä¸‹æ˜¾è‘—ä¼˜åŠ¿ï¼š

- **é«˜æ€§èƒ½æ•°æ®ä¼ è¾“** Spark-Flight-Connector ä½¿ç”¨ Apache Arrow ä½œä¸ºæ•°æ®ä¼ è¾“æ ¼å¼ï¼Œå®ç°é›¶æ‹·è´ã€é«˜æ•ˆçš„æ•°æ®äº¤æ¢ã€‚StarRocks çš„ `internal Block` æ•°æ®æ ¼å¼ä¸ Arrow ä¹‹é—´çš„è½¬æ¢éå¸¸é«˜æ•ˆï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„ `CSV` æˆ– `JDBC` æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¯è¾¾ 10 å€ï¼Œå¤§å¹…é™ä½æ•°æ®ä¼ è¾“å¼€é”€ã€‚
- **å¯¹å¤æ‚æ•°æ®ç±»å‹çš„åŸç”Ÿæ”¯æŒ** Arrow æ•°æ®æ ¼å¼åŸç”Ÿæ”¯æŒå¤æ‚ç±»å‹ï¼ˆå¦‚ `Map`ã€`Array`ã€`Struct` ç­‰ï¼‰ï¼Œä¸ä¼ ç»Ÿ JDBC æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº” StarRocks çš„å¤æ‚æ•°æ®æ¨¡å‹ï¼Œå¢å¼ºæ•°æ®çš„è¡¨è¾¾èƒ½åŠ›å’Œå…¼å®¹æ€§ã€‚
- **æ”¯æŒè¯»ã€å†™å’Œæµå¼å†™å…¥** è¯¥ç»„ä»¶æ”¯æŒ Spark ä½œä¸º Flight SQL å®¢æˆ·ç«¯è¿›è¡Œé«˜æ•ˆçš„è¯»å†™æ“ä½œï¼ŒåŒ…æ‹¬ `insert`ã€`merge`ã€`update` å’Œ `delete` DML è¯­å¥ï¼Œç”šè‡³æ”¯æŒæµå¼å†™å…¥ï¼Œé€‚ç”¨äºå®æ—¶æ•°æ®å¤„ç†åœºæ™¯ã€‚
- **æ”¯æŒè°“è¯ä¸‹æ¨å’Œåˆ—è£å‰ª** åœ¨è¯»å–æ•°æ®æ—¶ï¼ŒSpark-Flight-Connector æ”¯æŒè°“è¯ä¸‹æ¨å’Œåˆ—è£å‰ªï¼Œèƒ½å¤Ÿåœ¨ StarRocks ç«¯è¿›è¡Œæ•°æ®è¿‡æ»¤å’Œåˆ—é€‰æ‹©ï¼Œå¤§å¹…å‡å°‘ä¼ è¾“æ•°æ®é‡ï¼Œæé«˜æŸ¥è¯¢æ€§èƒ½ã€‚
- **æ”¯æŒèšåˆä¸‹æ¨å’Œå¹¶è¡Œè¯»å–** èšåˆæ“ä½œï¼ˆå¦‚ `sum`ã€`count`ã€`max`ã€`min` ç­‰ï¼‰å¯ä»¥ä¸‹æ¨åˆ° StarRocks æ‰§è¡Œï¼Œå‡å°‘ Spark çš„è®¡ç®—è´Ÿæ‹…ã€‚åŒæ—¶æ”¯æŒåŸºäºåˆ†åŒºçš„å¹¶è¡Œè¯»å–ï¼Œæé«˜å¤§æ•°æ®åœºæ™¯ä¸‹çš„è¯»å–æ•ˆç‡ã€‚
- **æ›´é€‚åˆå¤§æ•°æ®åœºæ™¯** ç›¸è¾ƒäºä¼ ç»Ÿ JDBC æ–¹æ³•ï¼ŒFlight SQL åè®®æ›´é€‚åˆå¤§è§„æ¨¡ã€é«˜å¹¶å‘è®¿é—®åœºæ™¯ï¼Œä½¿ StarRocks èƒ½å¤Ÿå……åˆ†å‘æŒ¥å…¶é«˜æ€§èƒ½åˆ†æèƒ½åŠ›ã€‚

## é™„å½•

ä»¥ä¸‹æ˜¯ä½¿ç”¨æ•™ç¨‹ä¸­çš„å®Œæ•´ä»£ç ç¤ºä¾‹ã€‚

```Python
# =============================================================================
# StarRocks Arrow Flight SQL Test Script
# =============================================================================
# pip install adbc_driver_manager adbc_driver_flightsql pandas
# =============================================================================

# =============================================================================
# Required core modules for connecting to StarRocks via Arrow Flight SQL
# =============================================================================
import adbc_driver_manager
import adbc_driver_flightsql.dbapi as flight_sql

# =============================================================================
# Optional modules for better usability and debugging
# =============================================================================
import pandas as pd       # å¯é€‰ï¼šä½¿ç”¨ DataFrame æ›´å¥½åœ°æ˜¾ç¤ºç»“æœ
import traceback          # å¯é€‰ï¼šåœ¨ SQL æ‰§è¡ŒæœŸé—´æä¾›è¯¦ç»†çš„é”™è¯¯è¿½è¸ª
import time               # å¯é€‰ï¼šç”¨äºæµ‹é‡ SQL æ‰§è¡Œæ—¶é—´

# =============================================================================
# StarRocks Flight SQL Configuration
# =============================================================================
FE_HOST = "127.0.0.1"
FE_PORT = 9408

# =============================================================================
# Connect to StarRocks
# =============================================================================
conn = flight_sql.connect(
    uri=f"grpc://{FE_HOST}:{FE_PORT}",
    db_kwargs={
        adbc_driver_manager.DatabaseOptions.USERNAME.value: "root",
        adbc_driver_manager.DatabaseOptions.PASSWORD.value: "",
    }
)

cursor = conn.cursor()

# =============================================================================
# Utility functions for better output formatting and SQL execution
# =============================================================================

def print_header(title: str):
    """
    æ‰“å°éƒ¨åˆ†æ ‡é¢˜ä»¥æé«˜å¯è¯»æ€§ã€‚
    """
    print("\n" + "=" * 80)
    print(f"ğŸŸ¢ {title}")
    print("=" * 80)


def print_sql(sql: str):
    """
    åœ¨æ‰§è¡Œå‰æ‰“å° SQL è¯­å¥ã€‚
    """
    print(f"\nğŸŸ¡ SQL:\n{sql.strip()}")


def print_result(df: pd.DataFrame):
    """
    ä»¥å¯è¯»æ ¼å¼æ‰“å°ç»“æœ DataFrameã€‚
    """
    if df.empty:
        print("\nğŸŸ¢ Result: (no rows returned)\n")
    else:
        print("\nğŸŸ¢ Result:\n")
        print(df.to_string(index=False))


def print_error(e: Exception):
    """
    å¦‚æœ SQL æ‰§è¡Œå¤±è´¥ï¼Œæ‰“å°é”™è¯¯è¿½è¸ªã€‚
    """
    print("\nğŸ”´ Error occurred:")
    traceback.print_exc()


def execute(sql: str):
    """
    æ‰§è¡Œ SQL è¯­å¥å¹¶æ‰“å°ç»“æœå’Œæ‰§è¡Œæ—¶é—´ã€‚
    """
    print_sql(sql)
    try:
        start = time.time()  # å¼€å§‹æ—¶é—´ç”¨äºæµ‹é‡æ‰§è¡Œæ—¶é—´
        cursor.execute(sql)
        result = cursor.fetchallarrow()  # Arrow Table
        df = result.to_pandas()          # è½¬æ¢ä¸º DataFrame ä»¥æ›´å¥½åœ°æ˜¾ç¤º
        print_result(df)
        print(f"\nâ±ï¸  Execution time: {time.time() - start:.3f} seconds")
    except Exception as e:
        print_error(e)

# =============================================================================
# Step 1: Drop and Create Database
# =============================================================================
print_header("Step 1: Drop and Create Database")
execute("DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;")
execute("SHOW DATABASES;")
execute("CREATE DATABASE sr_arrow_flight_sql;")
execute("SHOW DATABASES;")
execute("USE sr_arrow_flight_sql;")

# =============================================================================
# Step 2: Create Table
# =============================================================================
print_header("Step 2: Create Table")
execute("""
CREATE TABLE sr_arrow_flight_sql_test
(
    k0 INT,
    k1 DOUBLE,
    k2 VARCHAR(32) NULL DEFAULT "" COMMENT "",
    k3 DECIMAL(27,9) DEFAULT "0",
    k4 BIGINT NULL DEFAULT '10',
    k5 DATE
)
DISTRIBUTED BY HASH(k5) BUCKETS 5
PROPERTIES("replication_num" = "1");
""")

execute("SHOW CREATE TABLE sr_arrow_flight_sql_test;")

# =============================================================================
# Step 3: Insert Data
# =============================================================================
print_header("Step 3: Insert Data")
execute("""
INSERT INTO sr_arrow_flight_sql_test VALUES
    (0, 0.1, "ID", 0.0001, 1111111111, '2025-04-21'),
    (1, 0.20, "ID_1", 1.00000001, 0, '2025-04-21'),
    (2, 3.4, "ID_1", 3.1, 123456, '2025-04-22'),
    (3, 4, "ID", 4, 4, '2025-04-22'),
    (4, 122345.54321, "ID", 122345.54321, 5, '2025-04-22');
""")

# =============================================================================
# Step 4: Query Data
# =============================================================================
print_header("Step 4: Query Data")
execute("SELECT * FROM sr_arrow_flight_sql_test ORDER BY k0;")

# =============================================================================
# Step 5: Session Variables
# =============================================================================
print_header("Step 5: Session Variables")
execute("SHOW VARIABLES LIKE '%query_mem_limit%';")
execute("SET query_mem_limit = 2147483648;")
execute("SHOW VARIABLES LIKE '%query_mem_limit%';")

# =============================================================================
# Step 6: Aggregation Query
# =============================================================================
print_header("Step 6: Aggregation Query")
execute("""
SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
FROM sr_arrow_flight_sql_test
GROUP BY k5
ORDER BY k5;
""")

# =============================================================================
# Step 7: Close Connection
# =============================================================================
print_header("Step 7: Close Connection")
cursor.close()
conn.close()
print("âœ… Test completed successfully.")
```