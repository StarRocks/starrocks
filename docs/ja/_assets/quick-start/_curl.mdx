StarRocks Stream Load と curl は多くの引数を取ります。このチュートリアルで使用されるものだけがここで説明されており、残りは詳細情報セクションでリンクされます。

#### `--location-trusted`

これは、curl がリダイレクトされた URL に資格情報を渡すように設定します。

#### `-u root`

StarRocks にログインするために使用されるユーザー名です。

#### `-T filename`

T は転送を意味し、転送するファイル名です。

#### `label:name-num`

この Stream Load ジョブに関連付けるラベルです。ラベルは一意である必要があるため、ジョブを複数回実行する場合は、番号を追加してインクリメントし続けることができます。

#### `column_separator:,`

ファイルが単一の `,` を使用している場合は、上記のように設定します。異なる区切り文字を使用する場合は、その区切り文字をここに設定します。一般的な選択肢は `\t`、`,`、`|` です。

#### `skip_header:1`

一部の CSV ファイルには、すべての列名が記載された単一のヘッダー行があり、データ型を含む2行目を追加するものもあります。ヘッダー行が1行または2行ある場合は skip_header を `1` または `2` に設定し、ない場合は `0` に設定します。

#### `enclose:\"`

埋め込みカンマを含む文字列をダブルクォートで囲むことが一般的です。このチュートリアルで使用されるサンプルデータセットにはカンマを含む地理的位置があるため、enclose 設定は `\"` に設定されています。`"` を `\` でエスケープすることを忘れないでください。

#### `max_filter_ratio:1`

これはデータ内のいくつかのエラーを許可します。理想的には `0` に設定し、エラーがある場合はジョブが失敗するようにします。デバッグ中にすべての行が失敗することを許可するために `1` に設定されています。

#### `columns:`

CSV ファイルの列を StarRocks テーブルの列にマッピングします。CSV ファイルにはテーブルの列よりも多くの列があることに気付くでしょう。テーブルに含まれていない列はスキップされます。

また、クラッシュデータセットの `columns:` 行にデータの変換が含まれていることにも気付くでしょう。CSV ファイルには標準に準拠していない日付や時刻が含まれていることが非常に一般的です。これは、クラッシュの日時を DATETIME 型に変換するためのロジックです。

##### The columns line

これは1つのデータレコードの始まりです。日付は `MM/DD/YYYY` 形式で、時刻は `HH:MI` です。DATETIME は通常 `YYYY-MM-DD HH:MI:SS` であるため、このデータを変換する必要があります。

```plaintext
08/05/2014,9:10,BRONX,10469,40.8733019,-73.8536375,"(40.8733019, -73.8536375)",
```

これは `columns:` パラメータの始まりです。

```bash
-H "columns:tmp_CRASH_DATE, tmp_CRASH_TIME, CRASH_DATE=str_to_date(concat_ws(' ', tmp_CRASH_DATE, tmp_CRASH_TIME), '%m/%d/%Y %H:%i')
```

これは StarRocks に次のことを指示します:
- CSV ファイルの最初の列の内容を `tmp_CRASH_DATE` に割り当てる
- CSV ファイルの2番目の列の内容を `tmp_CRASH_TIME` に割り当てる
- `concat_ws()` は `tmp_CRASH_DATE` と `tmp_CRASH_TIME` をスペースで連結する
- `str_to_date()` は連結された文字列から DATETIME を作成する
- 結果の DATETIME を `CRASH_DATE` 列に格納する