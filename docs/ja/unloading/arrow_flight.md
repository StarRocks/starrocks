---
displayed_sidebar: docs
---

# Arrow Flight SQL ã‚’ä»‹ã—ã¦ StarRocks ã¨å¯¾è©±ã™ã‚‹

v3.5.1 ä»¥é™ã€StarRocks ã¯ Apache Arrow Flight SQL ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä»‹ã—ãŸæ¥ç¶šã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

Arrow Flight SQL ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯æ¬¡ã®åˆ©ç‚¹ã‚’ã‚‚ãŸã‚‰ã—ã¾ã™:

- ADBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¾ãŸã¯ Arrow Flight SQL JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ä»‹ã—ã¦é€šå¸¸ã® DDLã€DMLã€DQL ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚
- Python ã‚³ãƒ¼ãƒ‰ã¾ãŸã¯ Java ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€Arrow Flight SQL ADBC ã¾ãŸã¯ JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ä»‹ã—ã¦å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ã“ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€StarRocks ã®ã‚«ãƒ©ãƒ å‹å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®å®Œå…¨ãªã‚«ãƒ©ãƒ å‹ãƒ‡ãƒ¼ã‚¿è»¢é€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã€å¾“æ¥ã® JDBC ãŠã‚ˆã³ ODBC ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ä¸€èˆ¬çš„ã«è¦‹ã‚‰ã‚Œã‚‹é »ç¹ãªè¡Œ-ã‚«ãƒ©ãƒ å¤‰æ›ã¨ã‚·ãƒªã‚¢ãƒ«åŒ–ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’æ’é™¤ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€StarRocks ã¯ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ã€ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã€é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã§ãƒ‡ãƒ¼ã‚¿ã‚’è»¢é€ã§ãã¾ã™ã€‚

![Arrow Flight](../_assets/arrow_flight.png)

## ä½¿ç”¨æ–¹æ³•

Python ADBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ Arrow Flight SQL ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä»‹ã—ã¦ StarRocks ã«æ¥ç¶šã—ã€å¯¾è©±ã™ã‚‹ãŸã‚ã®æ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„ã€‚å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ä¾‹ã«ã¤ã„ã¦ã¯ [Appendix](#appendix) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

:::note

Python 3.9 ä»¥ä¸ŠãŒå‰ææ¡ä»¶ã§ã™ã€‚

:::

### ã‚¹ãƒ†ãƒƒãƒ— 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

`pip` ã‚’ä½¿ç”¨ã—ã¦ PyPI ã‹ã‚‰ `adbc_driver_manager` ã¨ `adbc_driver_flightsql` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:

```Bash
pip install adbc_driver_manager
pip install adbc_driver_flightsql
```

æ¬¡ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¾ãŸã¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚³ãƒ¼ãƒ‰ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™:

- å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª:

```Python
import adbc_driver_manager
import adbc_driver_flightsql.dbapi as flight_sql
```

- ä½¿ã„ã‚„ã™ã•ã¨ãƒ‡ãƒãƒƒã‚°ã®ãŸã‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«:

```Python
import pandas as pd       # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: DataFrame ã‚’ä½¿ç”¨ã—ãŸçµæœè¡¨ç¤ºã®å‘ä¸Š
import traceback          # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: SQL å®Ÿè¡Œä¸­ã®è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯
import time               # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: SQL å®Ÿè¡Œæ™‚é–“ã®æ¸¬å®š
```

### ã‚¹ãƒ†ãƒƒãƒ— 2. StarRocks ã«æ¥ç¶šã™ã‚‹

:::note

- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¦ FE ã‚µãƒ¼ãƒ“ã‚¹ã‚’é–‹å§‹ã—ãŸã„å ´åˆã¯ã€æ¬¡ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã‚’ä½¿ç”¨ã§ãã¾ã™:

  - ç’°å¢ƒå¤‰æ•° `JAVA_TOOL_OPTIONS` ã‚’æŒ‡å®šã—ã¾ã™ã€‚

    ```Bash
    export JAVA_TOOL_OPTIONS="--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED"
    ```

  - **fe.conf** ã§ FE è¨­å®šé …ç›® `JAVA_OPTS` ã‚’æŒ‡å®šã—ã¾ã™ã€‚ã“ã®æ–¹æ³•ã§ã¯ã€ä»–ã® `JAVA_OPTS` å€¤ã‚’è¿½åŠ ã§ãã¾ã™ã€‚

    ```Bash
    JAVA_OPTS="--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED ..."
    ```

- IntelliJ IDEA ã§ã‚µãƒ¼ãƒ“ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹å ´åˆã¯ã€`Run/Debug Configurations` ã® `Build and run` ã«æ¬¡ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:

  ```Bash
  --add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED
  ```

:::

#### StarRocks ã®è¨­å®š

Arrow Flight SQL ã‚’ä»‹ã—ã¦ StarRocks ã«æ¥ç¶šã™ã‚‹å‰ã«ã€Arrow Flight SQL ã‚µãƒ¼ãƒ“ã‚¹ãŒæœ‰åŠ¹ã«ãªã‚Šã€æŒ‡å®šã•ã‚ŒãŸãƒãƒ¼ãƒˆã§ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã« FE ãŠã‚ˆã³ BE ãƒãƒ¼ãƒ‰ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

FE è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« **fe.conf** ã¨ BE è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« **be.conf** ã®ä¸¡æ–¹ã§ã€`arrow_flight_port` ã‚’åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆã«è¨­å®šã—ã¾ã™ã€‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›´ã—ãŸå¾Œã€FE ãŠã‚ˆã³ BE ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†èµ·å‹•ã—ã¦å¤‰æ›´ã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚

:::note

FE ã¨ BE ã«ã¯ç•°ãªã‚‹ `arrow_flight_port` ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

:::

ä¾‹:

```Properties
// fe.conf
arrow_flight_port = 9408
// be.conf
arrow_flight_port = 9419
```

#### æ¥ç¶šã®ç¢ºç«‹

ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§ã¯ã€æ¬¡ã®æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ Arrow Flight SQL ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã™:

- StarRocks FE ã®ãƒ›ã‚¹ãƒˆã‚¢ãƒ‰ãƒ¬ã‚¹
- StarRocks FE ã§ Arrow Flight ãŒãƒªã‚¹ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã™ã‚‹ãƒãƒ¼ãƒˆ
- å¿…è¦ãªæ¨©é™ã‚’æŒã¤ StarRocks ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰

ä¾‹:

```Python
FE_HOST = "127.0.0.1"
FE_PORT = 9408

conn = flight_sql.connect(
    uri=f"grpc://{FE_HOST}:{FE_PORT}",
    db_kwargs={
        adbc_driver_manager.DatabaseOptions.USERNAME.value: "root",
        adbc_driver_manager.DatabaseOptions.PASSWORD.value: "",
    }
)
cursor = conn.cursor()
```

æ¥ç¶šãŒç¢ºç«‹ã•ã‚ŒãŸå¾Œã€è¿”ã•ã‚ŒãŸã‚«ãƒ¼ã‚½ãƒ«ã‚’é€šã˜ã¦ SQL ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ StarRocks ã¨å¯¾è©±ã§ãã¾ã™ã€‚

### ã‚¹ãƒ†ãƒƒãƒ— 3. (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®äº‹å‰å®šç¾©

ã“ã‚Œã‚‰ã®é–¢æ•°ã¯å‡ºåŠ›ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¨™æº–åŒ–ã—ã€ãƒ‡ãƒãƒƒã‚°ã‚’ç°¡ç´ åŒ–ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ãƒ†ã‚¹ãƒˆã®ãŸã‚ã«ã‚³ãƒ¼ãƒ‰å†…ã§ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§å®šç¾©ã§ãã¾ã™ã€‚

```Python
# =============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°: å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å‘ä¸Šã¨ SQL å®Ÿè¡Œ
# =============================================================================

# ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å°åˆ·
def print_header(title: str):
    """
    èª­ã¿ã‚„ã™ã•ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å°åˆ·ã—ã¾ã™ã€‚
    """
    print("\n" + "=" * 80)
    print(f"ğŸŸ¢ {title}")
    print("=" * 80)

# å®Ÿè¡Œä¸­ã® SQL ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å°åˆ·
def print_sql(sql: str):
    """
    å®Ÿè¡Œå‰ã« SQL ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å°åˆ·ã—ã¾ã™ã€‚
    """
    print(f"\nğŸŸ¡ SQL:\n{sql.strip()}")

# çµæœã® DataFrame ã‚’å°åˆ·
def print_result(df: pd.DataFrame):
    """
    çµæœã® DataFrame ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã§å°åˆ·ã—ã¾ã™ã€‚
    """
    if df.empty:
        print("\nğŸŸ¢ Result: (no rows returned)\n")
    else:
        print("\nğŸŸ¢ Result:\n")
        print(df.to_string(index=False))

# ã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’å°åˆ·
def print_error(e: Exception):
    """
    SQL å®Ÿè¡ŒãŒå¤±æ•—ã—ãŸå ´åˆã«ã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’å°åˆ·ã—ã¾ã™ã€‚
    """
    print("\nğŸ”´ Error occurred:")
    traceback.print_exc()

# SQL ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã€çµæœã‚’å°åˆ·
def execute(sql: str):
    """
    SQL ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã€çµæœã¨å®Ÿè¡Œæ™‚é–“ã‚’å°åˆ·ã—ã¾ã™ã€‚
    """
    print_sql(sql)
    try:
        start = time.time()  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: å®Ÿè¡Œæ™‚é–“æ¸¬å®šã®é–‹å§‹æ™‚é–“
        cursor.execute(sql)
        result = cursor.fetchallarrow()  # Arrow Table
        df = result.to_pandas()  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: DataFrame ã«å¤‰æ›ã—ã¦è¡¨ç¤ºã‚’å‘ä¸Š
        print_result(df)
        print(f"\nâ±ï¸  Execution time: {time.time() - start:.3f} seconds")
    except Exception as e:
        print_error(e)
```

### ã‚¹ãƒ†ãƒƒãƒ— 4. StarRocks ã¨å¯¾è©±ã™ã‚‹

ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆã€ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã€ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã€å¤‰æ•°ã®è¨­å®šã€ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œãªã©ã®åŸºæœ¬æ“ä½œã‚’æ¡ˆå†…ã—ã¾ã™ã€‚

:::note

ä»¥ä¸‹ã«ç¤ºã™å‡ºåŠ›ä¾‹ã¯ã€å‰è¿°ã®ã‚¹ãƒ†ãƒƒãƒ—ã§èª¬æ˜ã—ãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã«åŸºã¥ã„ã¦å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚

:::

1. ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªã—ã¾ã™ã€‚

   ```Python
   # ã‚¹ãƒ†ãƒƒãƒ— 1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰Šé™¤ã¨ä½œæˆ
   print_header("Step 1: Drop and Create Database")
   execute("DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;")
   execute("SHOW DATABASES;")
   execute("CREATE DATABASE sr_arrow_flight_sql;")
   execute("SHOW DATABASES;")
   execute("USE sr_arrow_flight_sql;")
   
   # ã‚¹ãƒ†ãƒƒãƒ— 2: ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
   print_header("Step 2: Create Table")
   execute("""
   CREATE TABLE sr_arrow_flight_sql_test
   (
       k0 INT,
       k1 DOUBLE,
       k2 VARCHAR(32) NULL DEFAULT "" COMMENT "",
       k3 DECIMAL(27,9) DEFAULT "0",
       k4 BIGINT NULL DEFAULT '10',
       k5 DATE
   )
   DISTRIBUTED BY HASH(k5) BUCKETS 5
   PROPERTIES("replication_num" = "1");
   """)
   execute("SHOW CREATE TABLE sr_arrow_flight_sql_test;")
   ```

   å‡ºåŠ›ä¾‹:

   ```SQL
   ================================================================================
   ğŸŸ¢ Step 1: Drop and Create Database
   ================================================================================
   
   ğŸŸ¡ SQL:
   DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;
   /Users/starrocks/test/venv/lib/python3.9/site-packages/adbc_driver_manager/dbapi.py:307: Warning: Cannot disable autocommit; conn will not be DB-API 2.0 compliant
     warnings.warn(
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.025 seconds
   
   ğŸŸ¡ SQL:
   SHOW DATABASES;
   
   ğŸŸ¢ Result:
      
             Database
         _statistics_
                 hits
   information_schema
                  sys
   
   â±ï¸  Execution time: 0.014 seconds
   
   ğŸŸ¡ SQL:
   CREATE DATABASE sr_arrow_flight_sql;
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.012 seconds
   
   ğŸŸ¡ SQL:
   SHOW DATABASES;
   
   ğŸŸ¢ Result:
   
              Database
          _statistics_
                  hits
    information_schema
   sr_arrow_flight_sql
                   sys
   
   â±ï¸  Execution time: 0.005 seconds
   
   ğŸŸ¡ SQL:
   USE sr_arrow_flight_sql;
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.006 seconds
   
   ================================================================================
   ğŸŸ¢ Step 2: Create Table
   ================================================================================
   
   ğŸŸ¡ SQL:
   CREATE TABLE sr_arrow_flight_sql_test
   (
       k0 INT,
       k1 DOUBLE,
       k2 VARCHAR(32) NULL DEFAULT "" COMMENT "",
       k3 DECIMAL(27,9) DEFAULT "0",
       k4 BIGINT NULL DEFAULT '10',
       k5 DATE
   )
   DISTRIBUTED BY HASH(k5) BUCKETS 5
   PROPERTIES("replication_num" = "1");
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.021 seconds
   
   ğŸŸ¡ SQL:
   SHOW CREATE TABLE sr_arrow_flight_sql_test;
   
   ğŸŸ¢ Result:
   
                      Table                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Create Table
   sr_arrow_flight_sql_test CREATE TABLE `sr_arrow_flight_sql_test` (\n  `k0` int(11) NULL COMMENT "",\n  `k1` double NULL COMMENT "",\n  `k2` varchar(32) NULL DEFAULT "" COMMENT "",\n  `k3` decimal(27, 9) NULL DEFAULT "0" COMMENT "",\n  `k4` bigint(20) NULL DEFAULT "10" COMMENT "",\n  `k5` date NULL COMMENT ""\n) ENGINE=OLAP \nDUPLICATE KEY(`k0`)\nDISTRIBUTED BY HASH(`k5`) BUCKETS 5 \nPROPERTIES (\n"compression" = "LZ4",\n"fast_schema_evolution" = "true",\n"replicated_storage" = "true",\n"replication_num" = "1"\n);
   
   â±ï¸  Execution time: 0.005 seconds
   ```

2. ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ã—ã€ã„ãã¤ã‹ã®ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€å¤‰æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚

   ```Python
   # ã‚¹ãƒ†ãƒƒãƒ— 3: ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥
   print_header("Step 3: Insert Data")
   execute("""
   INSERT INTO sr_arrow_flight_sql_test VALUES
       (0, 0.1, "ID", 0.0001, 1111111111, '2025-04-21'),
       (1, 0.20, "ID_1", 1.00000001, 0, '2025-04-21'),
       (2, 3.4, "ID_1", 3.1, 123456, '2025-04-22'),
       (3, 4, "ID", 4, 4, '2025-04-22'),
       (4, 122345.54321, "ID", 122345.54321, 5, '2025-04-22');
   """)
   
   # ã‚¹ãƒ†ãƒƒãƒ— 4: ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ã‚¨ãƒª
   print_header("Step 4: Query Data")
   execute("SELECT * FROM sr_arrow_flight_sql_test ORDER BY k0;")
   
   # ã‚¹ãƒ†ãƒƒãƒ— 5: ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
   print_header("Step 5: Session Variables")
   execute("SHOW VARIABLES LIKE '%query_mem_limit%';")
   execute("SET query_mem_limit = 2147483648;")
   execute("SHOW VARIABLES LIKE '%query_mem_limit%';")
   
   # ã‚¹ãƒ†ãƒƒãƒ— 6: é›†è¨ˆã‚¯ã‚¨ãƒª
   print_header("Step 6: Aggregation Query")
   execute("""
   SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
   FROM sr_arrow_flight_sql_test
   GROUP BY k5
   ORDER BY k5;
   """)
   ```

   å‡ºåŠ›ä¾‹:

   ```SQL
   ================================================================================
   ğŸŸ¢ Step 3: Insert Data
   ================================================================================
   
   ğŸŸ¡ SQL:
   INSERT INTO sr_arrow_flight_sql_test VALUES
       (0, 0.1, "ID", 0.0001, 1111111111, '2025-04-21'),
       (1, 0.20, "ID_1", 1.00000001, 0, '2025-04-21'),
       (2, 3.4, "ID_1", 3.1, 123456, '2025-04-22'),
       (3, 4, "ID", 4, 4, '2025-04-22'),
       (4, 122345.54321, "ID", 122345.54321, 5, '2025-04-22');
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
   
   â±ï¸  Execution time: 0.149 seconds
   
   ================================================================================
   ğŸŸ¢ Step 4: Query Data
   ================================================================================
   
   ğŸŸ¡ SQL:
   SELECT * FROM sr_arrow_flight_sql_test ORDER BY k0;
   
   ğŸŸ¢ Result:
                                                                
   0      0.10000   ID      0.000100000 1111111111 2025-04-21
   1      0.20000 ID_1      1.000000010          0 2025-04-21
   2      3.40000 ID_1      3.100000000     123456 2025-04-22
   3      4.00000   ID      4.000000000          4 2025-04-22
   4 122345.54321   ID 122345.543210000          5 2025-04-22
   
   â±ï¸  Execution time: 0.019 seconds
   
   ================================================================================
   ğŸŸ¢ Step 5: Session Variables
   ================================================================================
   
   ğŸŸ¡ SQL:
   SHOW VARIABLES LIKE '%query_mem_limit%';
   
   ğŸŸ¢ Result:
   
     Variable_name Value
   query_mem_limit     0
   
   â±ï¸  Execution time: 0.005 seconds
   
   ğŸŸ¡ SQL:
   SET query_mem_limit = 2147483648;
   
   ğŸŸ¢ Result:
   
   StatusResult
              0
      
   â±ï¸  Execution time: 0.007 seconds
   
   ğŸŸ¡ SQL:
   SHOW VARIABLES LIKE '%query_mem_limit%';
   
   ğŸŸ¢ Result:
   
     Variable_name        Value
     query_mem_limit 2147483648
   
   â±ï¸  Execution time: 0.005 seconds
   
   ================================================================================
   ğŸŸ¢ Step 6: Aggregation Query
   ================================================================================
   
   ğŸŸ¡ SQL:
   SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
   FROM sr_arrow_flight_sql_test
   GROUP BY k5
   ORDER BY k5;
   
   ğŸŸ¢ Result:
                                                  
   2025-04-21      0.30000 2     0.500050005000
   2025-04-22 122352.94321 3 40784.214403333333
      
   â±ï¸  Execution time: 0.014 second
   ```

### ã‚¹ãƒ†ãƒƒãƒ— 5. æ¥ç¶šã‚’é–‰ã˜ã‚‹

æ¥ç¶šã‚’é–‰ã˜ã‚‹ãŸã‚ã«ã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚³ãƒ¼ãƒ‰ã«å«ã‚ã¾ã™ã€‚

```Python
# Step 7: Close
print_header("Step 7: Close Connection")
cursor.close()
conn.close()
print("âœ… Test completed successfully.")
```

å‡ºåŠ›ä¾‹:

```Python
================================================================================
ğŸŸ¢ Step 7: Close Connection
================================================================================
âœ… Test completed successfully.

Process finished with exit code 0
```

## å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿è»¢é€ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

### Python

ADBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ Python ã§ StarRocksï¼ˆArrow Flight SQL ã‚µãƒãƒ¼ãƒˆä»˜ãï¼‰ã«æ¥ç¶šã—ãŸå¾Œã€ã•ã¾ã–ã¾ãª ADBC API ã‚’ä½¿ç”¨ã—ã¦ StarRocks ã‹ã‚‰ Clickbench ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ Python ã«ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚

ã‚³ãƒ¼ãƒ‰ä¾‹:

```Python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import adbc_driver_manager
import adbc_driver_flightsql.dbapi as flight_sql
from datetime import datetime

# ----------------------------------------
# StarRocks Flight SQL Connection Settings
# ----------------------------------------
# Replace the URI and credentials as needed
my_uri = "grpc://127.0.0.1:9408"  # Default Flight SQL port for StarRocks
my_db_kwargs = {
    adbc_driver_manager.DatabaseOptions.USERNAME.value: "root",
    adbc_driver_manager.DatabaseOptions.PASSWORD.value: "",
}

# ----------------------------------------
# SQL Query (ClickBench: hits table)
# ----------------------------------------
# Replace with the actual table and dataset as needed
sql = "SELECT * FROM clickbench.hits LIMIT 1000000;"  # Read 1 million rows

# ----------------------------------------
# Method 1: fetchallarrow + to_pandas
# ----------------------------------------
def test_fetchallarrow():
    conn = flight_sql.connect(uri=my_uri, db_kwargs=my_db_kwargs)
    cursor = conn.cursor()
    start = datetime.now()
    cursor.execute(sql)
    arrow_table = cursor.fetchallarrow()
    df = arrow_table.to_pandas()
    duration = datetime.now() - start

    print("\n[Method 1] fetchallarrow + to_pandas")
    print(f"Time taken: {duration}, Arrow table size: {arrow_table.nbytes / 1024 / 1024:.2f} MB, Rows: {len(df)}")
    print(df.info(memory_usage='deep'))

# ----------------------------------------
# Method 2: fetch_df (recommended)
# ----------------------------------------
def test_fetch_df():
    conn = flight_sql.connect(uri=my_uri, db_kwargs=my_db_kwargs)
    cursor = conn.cursor()
    start = datetime.now()
    cursor.execute(sql)
    df = cursor.fetch_df()
    duration = datetime.now() - start

    print("\n[Method 2] fetch_df (recommended)")
    print(f"Time taken: {duration}, Rows: {len(df)}")
    print(df.info(memory_usage='deep'))

# ----------------------------------------
# Method 3: adbc_execute_partitions (for parallel read)
# ----------------------------------------
def test_execute_partitions():
    conn = flight_sql.connect(uri=my_uri, db_kwargs=my_db_kwargs)
    cursor = conn.cursor()
    start = datetime.now()
    partitions, schema = cursor.adbc_execute_partitions(sql)

    # Read the first partition (for demo)
    cursor.adbc_read_partition(partitions[0])
    arrow_table = cursor.fetchallarrow()
    df = arrow_table.to_pandas()
    duration = datetime.now() - start

    print("\n[Method 3] adbc_execute_partitions (parallel read)")
    print(f"Time taken: {duration}, Partitions: {len(partitions)}, Rows: {len(df)}")
    print(df.info(memory_usage='deep'))

# ----------------------------------------
# Run All Tests
# ----------------------------------------
if __name__ == "__main__":
    test_fetchallarrow()
    test_fetch_df()
    test_execute_partitions()
```

çµæœã¯ã€StarRocks ã‹ã‚‰ 1 ç™¾ä¸‡è¡Œã® Clickbench ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ105 åˆ—ã€780 MBï¼‰ã‚’èª­ã¿è¾¼ã‚€ã®ã«ã‚ãšã‹ 3 ç§’ã—ã‹ã‹ã‹ã‚‰ãªã‹ã£ãŸã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

```Python
[Method 1] fetchallarrow + to_pandas
Time taken: 0:00:03.219575, Arrow table size: 717.42 MB, Rows: 1000000
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000000 entries, 0 to 999999
Columns: 105 entries, CounterID to CLID
dtypes: int16(48), int32(19), int64(6), object(32)
memory usage: 2.4 GB

[Method 2] fetch_df (recommended)
Time taken: 0:00:02.358840, Rows: 1000000
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000000 entries, 0 to 999999
Columns: 105 entries, CounterID to CLID
dtypes: int16(48), int32(19), int64(6), object(32)
memory usage: 2.4 GB

[Method 3] adbc_execute_partitions (parallel read)
Time taken: 0:00:02.231144, Partitions: 1, Rows: 1000000
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000000 entries, 0 to 999999
Columns: 105 entries, CounterID to CLID
dtypes: int16(48), int32(19), int64(6), object(32)
memory usage: 2.4 GB
```

### Arrow Flight SQL JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼

Arrow Flight SQL ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯ã€æ¨™æº– JDBC ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨äº’æ›æ€§ã®ã‚ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã® JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã‚’ä½¿ç”¨ã—ã¦ã€Tableauã€Power BIã€DBeaver ãªã©ã®ã•ã¾ã–ã¾ãª BI ãƒ„ãƒ¼ãƒ«ã«ç°¡å˜ã«çµ±åˆã—ã€StarRocks ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚å¾“æ¥ã® JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¨åŒæ§˜ã«ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®å¤§ããªåˆ©ç‚¹ã¯ã€Apache Arrow ã«åŸºã¥ãé«˜é€Ÿãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€ã‚¯ã‚¨ãƒªã¨ãƒ‡ãƒ¼ã‚¿è»¢é€ã®åŠ¹ç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã§ã™ã€‚ä½¿ç”¨æ–¹æ³•ã¯å¾“æ¥ã® MySQL JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¨ã»ã¼åŒã˜ã§ã™ã€‚æ¥ç¶š URL ã§ `jdbc:mysql` ã‚’ `jdbc:arrow-flight-sql` ã«ç½®ãæ›ãˆã‚‹ã ã‘ã§ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚¯ã‚¨ãƒªçµæœã¯æ¨™æº–ã® `ResultSet` å½¢å¼ã§è¿”ã•ã‚Œã‚‹ãŸã‚ã€æ—¢å­˜ã® JDBC å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã¨ã®äº’æ›æ€§ãŒç¢ºä¿ã•ã‚Œã¾ã™ã€‚

:::note

Java 9 ä»¥é™ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã¯ã€Java ã‚³ãƒ¼ãƒ‰ã« `--add-opens=java.base/java.nio=ALL-UNNAMED` ã‚’è¿½åŠ ã—ã¦ JDK ã®å†…éƒ¨æ§‹é€ ã‚’å…¬é–‹ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã†ã—ãªã„ã¨ã€ç‰¹å®šã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¦ FE ã‚µãƒ¼ãƒ“ã‚¹ã‚’é–‹å§‹ã—ãŸã„å ´åˆã¯ã€æ¬¡ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã‚’ä½¿ç”¨ã§ãã¾ã™:

  - ç’°å¢ƒå¤‰æ•° `JAVA_TOOL_OPTIONS` ã‚’æŒ‡å®šã—ã¾ã™ã€‚

    ```Bash
    export JAVA_TOOL_OPTIONS="--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED"
    ```

  - **fe.conf** ã§ FE è¨­å®šé …ç›® `JAVA_OPTS` ã‚’æŒ‡å®šã—ã¾ã™ã€‚ã“ã®æ–¹æ³•ã§ã¯ã€ä»–ã® `JAVA_OPTS` å€¤ã‚’è¿½åŠ ã§ãã¾ã™ã€‚

    ```Bash
    JAVA_OPTS="--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED ..."
    ```

- IntelliJ IDEA ã§ãƒ‡ãƒãƒƒã‚°ã™ã‚‹å ´åˆã¯ã€`Run/Debug Configurations` ã® `Build and run` ã«æ¬¡ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:

  ```Bash
  --add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED
  ```

![Arrow Flight Example](../_assets/arrow_flight_example.png)

:::

<details>

  <summary><b>Click here to view the POM dependencies</b></summary>

```XML
<properties>
    <adbc.version>0.15.0</adbc.version>
</properties>

<dependencies>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-jdbc</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-core</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-manager</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-flight-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
</dependencies>
```

</details>

ã‚³ãƒ¼ãƒ‰ä¾‹:

```Java
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.Statement;

public class ArrowFlightSqlIntegrationTest {

    private static final String JDBC_URL = "jdbc:arrow-flight-sql://127.0.0.1:9408"
            + "?useEncryption=false"
            + "&useServerPrepStmts=false"
            + "&useSSL=false"
            + "&useArrowFlightSql=true";

    private static final String USER = "root";
    private static final String PASSWORD = "";

    private static int testCaseNum = 1;

    public static void main(String[] args) {
        try {
            // Load Arrow Flight SQL JDBC driver
            Class.forName("org.apache.arrow.driver.jdbc.ArrowFlightJdbcDriver");

            try (Connection conn = DriverManager.getConnection(JDBC_URL, USER, PASSWORD);
                    Statement stmt = conn.createStatement()) {

                testUpdate(stmt, "DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;");
                testQuery(stmt, "SHOW PROCESSLIST;");
                testUpdate(stmt, "CREATE DATABASE sr_arrow_flight_sql;");
                testQuery(stmt, "SHOW DATABASES;");
                testUpdate(stmt, "USE sr_arrow_flight_sql;");
                testUpdate(stmt, "CREATE TABLE sr_table_test (id INT, name STRING) ENGINE=OLAP PRIMARY KEY (id) " +
                        "DISTRIBUTED BY HASH(id) BUCKETS 1 " +
                        "PROPERTIES ('replication_num' = '1');");
                testUpdate(stmt, "INSERT INTO sr_table_test VALUES (1, 'Alice'), (2, 'Bob');");
                testQuery(stmt, "SELECT * FROM sr_arrow_flight_sql.sr_table_test;");
            }
        } catch (Exception e) {
            e.printStackTrace();
        }

    }

    /**
     * Executes a query and prints the result to the console.
     */
    private static void testQuery(Statement stmt, String sql) throws Exception {
        System.out.println("Test Case: " + testCaseNum);
        System.out.println("â–¶ Executing query: " + sql);
        ResultSet rs = stmt.executeQuery(sql);
        try {
            System.out.println("Result:");
            int columnCount = rs.getMetaData().getColumnCount();
            while (rs.next()) {
                for (int i = 1; i <= columnCount; i++) {
                    System.out.print(rs.getString(i) + "\t");
                }
                System.out.println();
            }
        } finally {
            rs.close();
        }
        testCaseNum++;
        System.out.println();
    }

    /**
     * Executes an update (DDL or DML) and prints the result to the console.
     */
    private static void testUpdate(Statement stmt, String sql) throws Exception {
        System.out.println("Test Case: " + testCaseNum);
        System.out.println("â–¶ Executing update: " + sql);
        stmt.executeUpdate(sql);
        System.out.println("Result: âœ… Success");
        testCaseNum++;
        System.out.println();
    }
}
```

å®Ÿè¡Œçµæœ:

```Bash
Test Case: 1
â–¶ Executing update: DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;
Result: âœ… Success

Test Case: 2
â–¶ Executing query: SHOW PROCESSLIST;
Result:
192.168.124.48_9010_1751449846872	16777217	root			Query	2025-07-02 18:46:49	0	OK	SHOW PROCESSLIST;	false	default_warehouse	

Test Case: 3
â–¶ Executing update: CREATE DATABASE sr_arrow_flight_sql;
Result: âœ… Success

Test Case: 4
â–¶ Executing query: SHOW DATABASES;
Result:
_statistics_	
information_schema	
sr_arrow_flight_sql	
sys	

Test Case: 5
â–¶ Executing update: USE sr_arrow_flight_sql;
Result: âœ… Success

Test Case: 6
â–¶ Executing update: CREATE TABLE sr_table_test (id INT, name STRING) ENGINE=OLAP PRIMARY KEY (id) DISTRIBUTED BY HASH(id) BUCKETS 1 PROPERTIES ('replication_num' = '1');
Result: âœ… Success

Test Case: 7
â–¶ Executing update: INSERT INTO sr_table_test VALUES (1, 'Alice'), (2, 'Bob');
Result: âœ… Success

Test Case: 8
â–¶ Executing query: SELECT * FROM sr_arrow_flight_sql.sr_table_test;
Result:
1	Alice	
2	Bob
```

### Java ADBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼

Arrow Flight SQL ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯ã€æ¨™æº– JDBC ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨äº’æ›æ€§ã®ã‚ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã® JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã‚’ä½¿ç”¨ã—ã¦ã€Tableauã€Power BIã€DBeaver ãªã©ã®ã•ã¾ã–ã¾ãª BI ãƒ„ãƒ¼ãƒ«ã«ç°¡å˜ã«çµ±åˆã—ã€StarRocks ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚å¾“æ¥ã® JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¨åŒæ§˜ã«ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®å¤§ããªåˆ©ç‚¹ã¯ã€Apache Arrow ã«åŸºã¥ãé«˜é€Ÿãƒ‡ãƒ¼ã‚¿è»¢é€ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€ã‚¯ã‚¨ãƒªã¨ãƒ‡ãƒ¼ã‚¿è»¢é€ã®åŠ¹ç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã§ã™ã€‚ä½¿ç”¨æ–¹æ³•ã¯å¾“æ¥ã® MySQL JDBC ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã¨ã»ã¼åŒã˜ã§ã™ã€‚

:::note

- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã—ã¦ FE ã‚µãƒ¼ãƒ“ã‚¹ã‚’é–‹å§‹ã—ãŸã„å ´åˆã¯ã€æ¬¡ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã‚’ä½¿ç”¨ã§ãã¾ã™:

  - ç’°å¢ƒå¤‰æ•° `JAVA_TOOL_OPTIONS` ã‚’æŒ‡å®šã—ã¾ã™ã€‚

    ```Bash
    export JAVA_TOOL_OPTIONS="--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED"
    ```

  - **fe.conf** ã§ FE è¨­å®šé …ç›® `JAVA_OPTS` ã‚’æŒ‡å®šã—ã¾ã™ã€‚ã“ã®æ–¹æ³•ã§ã¯ã€ä»–ã® `JAVA_OPTS` å€¤ã‚’è¿½åŠ ã§ãã¾ã™ã€‚

    ```Bash
    JAVA_OPTS="--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED ..."
    ```

- IntelliJ IDEA ã§ãƒ‡ãƒãƒƒã‚°ã™ã‚‹å ´åˆã¯ã€`Run/Debug Configurations` ã® `Build and run` ã«æ¬¡ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:

  ```Bash
  --add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED
  ```

:::

<details>

  <summary>POM dependencies</summary>

```XML
<properties>
    <adbc.version>0.15.0</adbc.version>
</properties>

<dependencies>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-jdbc</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-core</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-manager</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
    <dependency>
        <groupId>org.apache.arrow.adbc</groupId>
        <artifactId>adbc-driver-flight-sql</artifactId>
        <version>${adbc.version}</version>
    </dependency>
</dependencies>
```

</details>

Python ã¨åŒæ§˜ã«ã€Java ã§ã‚‚ç›´æ¥ ADBC ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ StarRocks ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ã€æœ€åˆã« FlightInfo ã‚’å–å¾—ã—ã€æ¬¡ã«å„ Endpoint ã«æ¥ç¶šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚

ã‚³ãƒ¼ãƒ‰ä¾‹:

```Java
public static void main(String[] args) throws Exception {
    try (BufferAllocator allocator = new RootAllocator()) {
        FlightSqlDriver driver = new FlightSqlDriver(allocator);

        Map<String, Object> parameters = new HashMap<>();
        String host = "localhost";
        int port = 9408;
        String uri = Location.forGrpcInsecure(host, port).getUri().toString();

        AdbcDriver.PARAM_URI.set(parameters, uri);
        AdbcDriver.PARAM_USERNAME.set(parameters, "root");
        AdbcDriver.PARAM_PASSWORD.set(parameters, "");

        try (AdbcDatabase database = driver.open(parameters);
                AdbcConnection connection = database.connect();
                AdbcStatement statement = connection.createStatement()) {

            statement.setSqlQuery("SHOW DATABASES;");

            try (AdbcStatement.QueryResult result = statement.executeQuery();
                    ArrowReader reader = result.getReader()) {

                int batchCount = 0;
                while (reader.loadNextBatch()) {
                    batchCount++;
                    VectorSchemaRoot root = reader.getVectorSchemaRoot();
                    System.out.println("Batch " + batchCount + ":");
                    System.out.println(root.contentToTSVString());
                }

                System.out.println("Total batches: " + batchCount);
            }
        }
    }
}
```

#### æ¨å¥¨äº‹é …

- ä¸Šè¨˜ã® 3 ã¤ã® Java Arrow Flight SQL æ¥ç¶šæ–¹æ³•ã®ã†ã¡:
  - å¾Œç¶šã®ãƒ‡ãƒ¼ã‚¿åˆ†æãŒè¡Œãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«ä¾å­˜ã™ã‚‹å ´åˆã¯ã€`jdbc:arrow-flight-sql` ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ã“ã‚Œã¯ JDBC ResultSet å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚
  - åˆ†æãŒ Arrow å½¢å¼ã¾ãŸã¯ä»–ã®ã‚«ãƒ©ãƒ å‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç›´æ¥å‡¦ç†ã§ãã‚‹å ´åˆã¯ã€Flight AdbcDriver ã¾ãŸã¯ Flight JdbcDriver ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ Arrow å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥è¿”ã—ã€è¡Œ-ã‚«ãƒ©ãƒ å¤‰æ›ã‚’å›é¿ã—ã€Arrow ã®æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿è§£æã‚’åŠ é€Ÿã—ã¾ã™ã€‚

- JDBC ResultSet ã¾ãŸã¯ Arrow å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã™ã‚‹ã‹ã©ã†ã‹ã«ã‹ã‹ã‚ã‚‰ãšã€è§£ææ™‚é–“ã¯é€šå¸¸ã€ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Šè‡ªä½“ã«è²»ã‚„ã•ã‚Œã‚‹æ™‚é–“ã‚ˆã‚Šã‚‚é•·ããªã‚Šã¾ã™ã€‚Arrow Flight SQL ãŒ `jdbc:mysql://` ã«å¯¾ã—ã¦æœŸå¾…ã•ã‚Œã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã•ãªã„å ´åˆã¯ã€ãƒ‡ãƒ¼ã‚¿è§£æã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’èª¿æŸ»ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

- ã™ã¹ã¦ã®æ¥ç¶šæ–¹æ³•ã«ãŠã„ã¦ã€JDK 17 ã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Šã¯ã€é€šå¸¸ã€JDK 1.8 ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã™ã€‚

- å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿å–ã‚‹å ´åˆã€Arrow Flight SQL ã¯é€šå¸¸ã€`jdbc:mysql://` ã‚ˆã‚Šã‚‚ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»ã—ã¾ã›ã‚“ã€‚ã—ãŸãŒã£ã¦ã€ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ãŒã‚ã‚‹å ´åˆã¯ã€Arrow Flight SQL ã‚’è©¦ã—ã¦ã¿ã‚‹ä¾¡å€¤ãŒã‚ã‚Šã¾ã™ã€‚

- ä¸Šè¨˜ã® 3 ã¤ã®æ¥ç¶šæ–¹æ³•ã«åŠ ãˆã¦ã€ãƒã‚¤ãƒ†ã‚£ãƒ– FlightClient ã‚’ä½¿ç”¨ã—ã¦ Arrow Flight Server ã«æ¥ç¶šã—ã€è¤‡æ•°ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã®ã‚ˆã‚ŠæŸ”è»Ÿãªä¸¦åˆ—èª­ã¿å–ã‚Šã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚Java Flight AdbcDriver ã¯ FlightClient ã®ä¸Šã«æ§‹ç¯‰ã•ã‚Œã¦ãŠã‚Šã€FlightClient ã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹ã‚ˆã‚Šã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚

### Spark

ç¾åœ¨ã€å…¬å¼ã® Arrow Flight ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ Spark ã¾ãŸã¯ Flink ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹äºˆå®šã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å°†æ¥çš„ã«ã¯ã€[starrocks-spark-connector](https://github.com/qwshen/spark-flight-connector) ãŒ Arrow Flight SQL ã‚’ä»‹ã—ã¦ StarRocks ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã‚’æ®µéšçš„ã«è¿½åŠ ã—ã€èª­ã¿å–ã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚

Spark ã§ StarRocks ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å ´åˆã€å¾“æ¥ã® JDBC ã¾ãŸã¯ Java ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æ–¹æ³•ã«åŠ ãˆã¦ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã® Spark-Flight-Connector ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€Spark DataSource ã¨ã—ã¦ StarRocks Flight SQL Server ã‹ã‚‰ç›´æ¥èª­ã¿æ›¸ãã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€Apache Arrow Flight ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«åŸºã¥ã„ã¦ãŠã‚Šã€æ¬¡ã®ã‚ˆã†ãªé‡è¦ãªåˆ©ç‚¹ãŒã‚ã‚Šã¾ã™:

- **é«˜æ€§èƒ½ãƒ‡ãƒ¼ã‚¿è»¢é€** Spark-Flight-Connector ã¯ Apache Arrow ã‚’ãƒ‡ãƒ¼ã‚¿è»¢é€å½¢å¼ã¨ã—ã¦ä½¿ç”¨ã—ã€ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ã§éå¸¸ã«åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿äº¤æ›ã‚’å®Ÿç¾ã—ã¾ã™ã€‚StarRocks ã® `internal Block` ãƒ‡ãƒ¼ã‚¿å½¢å¼ã¨ Arrow ã®é–“ã®å¤‰æ›ã¯éå¸¸ã«åŠ¹ç‡çš„ã§ã€å¾“æ¥ã® `CSV` ã‚„ `JDBC` æ–¹æ³•ã¨æ¯”è¼ƒã—ã¦æœ€å¤§ 10 å€ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’é”æˆã—ã€ãƒ‡ãƒ¼ã‚¿è»¢é€ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¾ã™ã€‚
- **è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿å‹ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆ** Arrow ãƒ‡ãƒ¼ã‚¿å½¢å¼ã¯è¤‡é›‘ãªå‹ï¼ˆ`Map`ã€`Array`ã€`Struct` ãªã©ï¼‰ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€å¾“æ¥ã® JDBC æ–¹æ³•ã¨æ¯”è¼ƒã—ã¦ StarRocks ã®è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šé©å¿œã—ã€ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¾åŠ›ã¨äº’æ›æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚
- **èª­ã¿å–ã‚Šã€æ›¸ãè¾¼ã¿ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãè¾¼ã¿ã®ã‚µãƒãƒ¼ãƒˆ** ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯ã€Spark ã‚’ Flight SQL ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã—ã¦ä½¿ç”¨ã—ã¦åŠ¹ç‡çš„ãªèª­ã¿å–ã‚Šã¨æ›¸ãè¾¼ã¿æ“ä½œã‚’ã‚µãƒãƒ¼ãƒˆã—ã€`insert`ã€`merge`ã€`update`ã€`delete` DML ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å«ã¿ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›¸ãè¾¼ã¿ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãŸã‚ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŠãƒªã‚ªã«é©ã—ã¦ã„ã¾ã™ã€‚
- **è¿°èªãƒ—ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ã¨ã‚«ãƒ©ãƒ ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚µãƒãƒ¼ãƒˆ** ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚‹éš›ã€Spark-Flight-Connector ã¯è¿°èªãƒ—ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ã¨ã‚«ãƒ©ãƒ ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€StarRocks å´ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ã‚«ãƒ©ãƒ é¸æŠã‚’å¯èƒ½ã«ã—ã€è»¢é€ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã€ã‚¯ã‚¨ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚
- **é›†è¨ˆãƒ—ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ã¨ä¸¦åˆ—èª­ã¿å–ã‚Šã®ã‚µãƒãƒ¼ãƒˆ** é›†è¨ˆæ“ä½œï¼ˆ`sum`ã€`count`ã€`max`ã€`min` ãªã©ï¼‰ã¯ StarRocks ã«ãƒ—ãƒƒã‚·ãƒ¥ãƒ€ã‚¦ãƒ³ã—ã¦å®Ÿè¡Œã§ãã€Spark ã®è¨ˆç®—è² è·ã‚’è»½æ¸›ã—ã¾ã™ã€‚ã¾ãŸã€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã«åŸºã¥ãä¸¦åˆ—èª­ã¿å–ã‚Šã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚·ãƒŠãƒªã‚ªã§ã®èª­ã¿å–ã‚ŠåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚
- **å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚·ãƒŠãƒªã‚ªã«é©ã—ã¦ã„ã‚‹** å¾“æ¥ã® JDBC æ–¹æ³•ã¨æ¯”è¼ƒã—ã¦ã€Flight SQL ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯å¤§è¦æ¨¡ã§é«˜ã„åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ã‚·ãƒŠãƒªã‚ªã«ã‚ˆã‚Šé©ã—ã¦ãŠã‚Šã€StarRocks ãŒãã®é«˜æ€§èƒ½ãªåˆ†æèƒ½åŠ›ã‚’ååˆ†ã«æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

## Appendix

ä»¥ä¸‹ã¯ã€ä½¿ç”¨æ–¹æ³•ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«ãŠã‘ã‚‹å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ä¾‹ã§ã™ã€‚

```Python
# =============================================================================
# StarRocks Arrow Flight SQL Test Script
# =============================================================================
# pip install adbc_driver_manager adbc_driver_flightsql pandas
# =============================================================================

# =============================================================================
# Required core modules for connecting to StarRocks via Arrow Flight SQL
# =============================================================================
import adbc_driver_manager
import adbc_driver_flightsql.dbapi as flight_sql

# =============================================================================
# Optional modules for better usability and debugging
# =============================================================================
import pandas as pd       # Optional: for better result display using DataFrame
import traceback          # Optional: for detailed error traceback during SQL execution
import time               # Optional: for measuring SQL execution time

# =============================================================================
# StarRocks Flight SQL Configuration
# =============================================================================
FE_HOST = "127.0.0.1"
FE_PORT = 9408

# =============================================================================
# Connect to StarRocks
# =============================================================================
conn = flight_sql.connect(
    uri=f"grpc://{FE_HOST}:{FE_PORT}",
    db_kwargs={
        adbc_driver_manager.DatabaseOptions.USERNAME.value: "root",
        adbc_driver_manager.DatabaseOptions.PASSWORD.value: "",
    }
)

cursor = conn.cursor()

# =============================================================================
# Utility functions for better output formatting and SQL execution
# =============================================================================

def print_header(title: str):
    """
    Print a section header for better readability.
    """
    print("\n" + "=" * 80)
    print(f"ğŸŸ¢ {title}")
    print("=" * 80)


def print_sql(sql: str):
    """
    Print the SQL statement before execution.
    """
    print(f"\nğŸŸ¡ SQL:\n{sql.strip()}")


def print_result(df: pd.DataFrame):
    """
    Print the result DataFrame in a readable format.
    """
    if df.empty:
        print("\nğŸŸ¢ Result: (no rows returned)\n")
    else:
        print("\nğŸŸ¢ Result:\n")
        print(df.to_string(index=False))


def print_error(e: Exception):
    """
    Print the error traceback if SQL execution fails.
    """
    print("\nğŸ”´ Error occurred:")
    traceback.print_exc()


def execute(sql: str):
    """
    Execute a SQL statement and print the result and execution time.
    """
    print_sql(sql)
    try:
        start = time.time()  # Start time for execution time measurement
        cursor.execute(sql)
        result = cursor.fetchallarrow()  # Arrow Table
        df = result.to_pandas()          # Convert to DataFrame for better display
        print_result(df)
        print(f"\nâ±ï¸  Execution time: {time.time() - start:.3f} seconds")
    except Exception as e:
        print_error(e)

# =============================================================================
# Step 1: Drop and Create Database
# =============================================================================
print_header("Step 1: Drop and Create Database")
execute("DROP DATABASE IF EXISTS sr_arrow_flight_sql FORCE;")
execute("SHOW DATABASES;")
execute("CREATE DATABASE sr_arrow_flight_sql;")
execute("SHOW DATABASES;")
execute("USE sr_arrow_flight_sql;")

# =============================================================================
# Step 2: Create Table
# =============================================================================
print_header("Step 2: Create Table")
execute("""
CREATE TABLE sr_arrow_flight_sql_test
(
    k0 INT,
    k1 DOUBLE,
    k2 VARCHAR(32) NULL DEFAULT "" COMMENT "",
    k3 DECIMAL(27,9) DEFAULT "0",
    k4 BIGINT NULL DEFAULT '10',
    k5 DATE
)
DISTRIBUTED BY HASH(k5) BUCKETS 5
PROPERTIES("replication_num" = "1");
""")

execute("SHOW CREATE TABLE sr_arrow_flight_sql_test;")

# =============================================================================
# Step 3: Insert Data
# =============================================================================
print_header("Step 3: Insert Data")
execute("""
INSERT INTO sr_arrow_flight_sql_test VALUES
    (0, 0.1, "ID", 0.0001, 1111111111, '2025-04-21'),
    (1, 0.20, "ID_1", 1.00000001, 0, '2025-04-21'),
    (2, 3.4, "ID_1", 3.1, 123456, '2025-04-22'),
    (3, 4, "ID", 4, 4, '2025-04-22'),
    (4, 122345.54321, "ID", 122345.54321, 5, '2025-04-22');
""")

# =============================================================================
# Step 4: Query Data
# =============================================================================
print_header("Step 4: Query Data")
execute("SELECT * FROM sr_arrow_flight_sql_test ORDER BY k0;")

# =============================================================================
# Step 5: Session Variables
# =============================================================================
print_header("Step 5: Session Variables")
execute("SHOW VARIABLES LIKE '%query_mem_limit%';")
execute("SET query_mem_limit = 2147483648;")
execute("SHOW VARIABLES LIKE '%query_mem_limit%';")

# =============================================================================
# Step 6: Aggregation Query
# =============================================================================
print_header("Step 6: Aggregation Query")
execute("""
SELECT k5, SUM(k1) AS total_k1, COUNT(1) AS row_count, AVG(k3) AS avg_k3
FROM sr_arrow_flight_sql_test
GROUP BY k5
ORDER BY k5;
""")

# =============================================================================
# Step 7: Close Connection
# =============================================================================
print_header("Step 7: Close Connection")
cursor.close()
conn.close()
print("âœ… Test completed successfully.")
```