---
displayed_sidebar: docs
---
import DataLakeIntro from '../_assets/commonMarkdown/datalakeIntro.mdx'

# Data Lakehouse

<DataLakeIntro />

## Key ideas

- オープンデータフォーマット: JSON、Parquet、Avro などの多様なデータタイプをサポートし、構造化データと非構造化データの両方の保存と処理を容易にします。
- メタデータ管理: Iceberg テーブルフォーマットのようなフォーマットを利用して、共有メタデータレイヤーを実装し、データを効率的に整理・管理します。
- ガバナンスとセキュリティ: データのセキュリティ、プライバシー、コンプライアンスのための強力な組み込みメカニズムを備え、データの整合性と信頼性を確保します。

## Data Lakehouse アーキテクチャの利点

- 柔軟性とスケーラビリティ: 多様なデータタイプをシームレスに管理し、組織のニーズに応じてスケールします。
- コスト効率: 従来の方法と比較して、データの保存と処理のための経済的な代替手段を提供します。
- データガバナンスの強化: データの制御、管理、整合性を改善し、信頼性とセキュリティのあるデータ処理を実現します。
- AI と分析の準備: 機械学習や AI 駆動のデータ処理を含む複雑な分析タスクに最適です。

## StarRocks のアプローチ

考慮すべき重要な点は次のとおりです:

- catalog またはメタデータサービスとの統合の標準化
- コンピュートノードの弾力的なスケーラビリティ
- 柔軟なキャッシングメカニズム

---

## Catalogs

StarRocks には内部と外部の 2 種類の catalog があります。内部 catalog には StarRocks データベース内に保存されたデータのメタデータが含まれています。外部 catalog は、Hive、Iceberg、Delta Lake、Hudi によって管理されるデータを含む、外部に保存されたデータを操作するために使用されます。他にも多くの外部システムがあり、リンクはページ下部の「More Information」セクションにあります。

## Compute node (CN) のスケーリング

ストレージとコンピュートの分離により、スケーリングの複雑さが軽減されます。StarRocks のコンピュートノードはローカルキャッシュのみを保存しているため、ロードに応じてノードを追加または削除できます。

## Data cache

コンピュートノード上のキャッシュはオプションです。もしコンピュートノードが急速に変化するロードパターンに基づいて迅速にスピンアップおよびダウンしている場合や、クエリが頻繁に最新のデータのみに対して行われる場合、データをキャッシュすることは意味がないかもしれません。

詳細は [Catalog docs](../data_source/catalog/catalog_intro.mdx) にあります。