// Copyright 2021-present StarRocks, Inc. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#pragma once

#include "base/utility/defer_op.h"
#include "column/array_column.h"
#include "column/column_helper.h"
#include "column/hash_set.h"
#include "column/struct_column.h"
#include "column/type_traits.h"
#include "exec/sorting/sorting.h"
#include "exprs/agg/aggregate.h"
#include "exprs/function_context.h"
#include "runtime/mem_pool.h"
#include "runtime/runtime_state.h"
#include "types/logical_type.h"

namespace starrocks {
template <LogicalType PT, bool is_distinct, typename MyHashSet = std::set<int>>
struct ArrayAggAggregateState {
    using ColumnType = RunTimeColumnType<PT>;
    using CppType = RunTimeCppType<PT>;
    using KeyType = typename SliceHashSet::key_type;

    void update(MemPool* mem_pool, const ColumnType& column, size_t offset, size_t count) {
        if constexpr (is_distinct) {
            if constexpr (lt_is_string<PT>) {
                for (int i = 0; i < count; i++) {
                    auto raw_key = column.get_slice(offset + i);
                    KeyType key(raw_key);
#if defined(__clang__) && (__clang_major__ >= 16)
                    set.lazy_emplace(key, [&](const auto& ctor) {
#else
                    set.template lazy_emplace(key, [&](const auto& ctor) {
#endif
                        uint8_t* pos = mem_pool->allocate_with_reserve(key.size, SLICE_MEMEQUAL_OVERFLOW_PADDING);
                        assert(pos != nullptr);
                        memcpy(pos, key.data, key.size);
                        ctor(pos, key.size, key.hash);
                    });
                }
            } else {
                const auto datas = column.immutable_data();
                for (int i = 0; i < count; i++) {
                    set.emplace(datas[offset + i]);
                }
            }
        } else {
            data_column.append(column, offset, count);
        }
    }

    void append_null() {
        if constexpr (is_distinct) {
            null_count = 1;
        } else {
            null_count++;
        }
    }

    void append_null(size_t count) {
        if constexpr (is_distinct) {
            if (count > 0) {
                null_count = 1;
            }
        } else {
            null_count += count;
        }
    }

    ColumnType* get_data_column() {
        auto size = set.size();
        if (data_column.size() > 0 || size == 0) {
            return &data_column;
        }
        data_column.get_data().reserve(size);
        if constexpr (is_distinct) {
            if constexpr (lt_is_string<PT>) {
                for (auto& key : set) {
                    data_column.append(Slice(key.data, key.size));
                }
            } else {
                for (auto& key : set) {
                    data_column.append(key);
                }
            }
        }
        return &data_column;
    }

    bool check_overflow(FunctionContext* ctx) const { return check_overflow(data_column, ctx); }

    static bool check_overflow(const Column& col, FunctionContext* ctx) {
        Status st = col.capacity_limit_reached();
        if (!st.ok()) {
            ctx->set_error(fmt::format("The column generated by array_agg is overflow: {}", st.message()).c_str());
            return true;
        }
        return false;
    }

    void reset() {
        data_column.resize(0);
        null_count = 0;
        set.clear();
    }

    ColumnType data_column; // Aggregated elements for array_agg
    size_t null_count = 0;
    MyHashSet set;
};

template <LogicalType PT, typename = guard::Guard>
struct WithMemPool {};

template <LogicalType PT>
struct WithMemPool<PT, StringLTGuard<PT>> {
    MemPool mem_pool{};
};

template <LogicalType PT, bool is_distinct, typename MyHashSet = std::set<int>>
struct ArrayAggWindowState : public ArrayAggAggregateState<PT, is_distinct, MyHashSet>, WithMemPool<PT> {
    using Base = ArrayAggAggregateState<PT, is_distinct, MyHashSet>;
    using Self = ArrayAggWindowState<PT, is_distinct, MyHashSet>;
    using CppType = typename Base::CppType;
    using ColumnType = typename Base::ColumnType;
    using Base::update;
    using Base::append_null;
    using Base::reset;

    void update(MemPool* mem_pool, const ColumnType& column, size_t offset, size_t count) {
        if constexpr (lt_is_string<PT>) {
            this->Base::update(&this->mem_pool, column, offset, count);
        } else {
            this->Base::update(nullptr, column, offset, count);
        }
    }

    void reset() {
        this->Base::reset();
        if constexpr (lt_is_string<PT>) {
            this->mem_pool.clear();
        }
    }
};

template <LogicalType LT, bool is_distinct, template <LogicalType, bool, typename> typename State,
          typename MyHashSet = std::set<int>>
class ArrayAggAggregateFunctionBase final
        : public AggregateFunctionBatchHelper<State<LT, is_distinct, MyHashSet>,
                                              ArrayAggAggregateFunctionBase<LT, is_distinct, State, MyHashSet>> {
public:
    using InputColumnType = RunTimeColumnType<LT>;

    void update(FunctionContext* ctx, const Column** columns, AggDataPtr __restrict state,
                size_t row_num) const override {
        const auto& column = down_cast<const InputColumnType&>(*columns[0]);
        // TODO: update is random access, so we could not pre-reserve memory for State, which is the bottleneck
        this->data(state).update(ctx->mem_pool(), column, row_num, 1);
    }

    void process_null(FunctionContext* ctx, AggDataPtr __restrict state) const override {
        this->data(state).append_null();
    }

    void merge(FunctionContext* ctx, const Column* column, AggDataPtr __restrict state, size_t row_num) const override {
        // Array element is nullable, so we need to extract the data from nullable column first
        const auto* input_column = down_cast<const ArrayColumn*>(column);
        auto offset_size = input_column->get_element_offset_size(row_num);
        auto& array_element = down_cast<const NullableColumn&>(input_column->elements());
        auto* element_data_column = down_cast<const InputColumnType*>(ColumnHelper::get_data_column(&array_element));
        size_t element_null_count = array_element.null_count(offset_size.first, offset_size.second);
        DCHECK_LE(element_null_count, offset_size.second);

        this->data(state).update(ctx->mem_pool(), *element_data_column, offset_size.first,
                                 offset_size.second - element_null_count);
        this->data(state).append_null(element_null_count);
    }

    void serialize_to_column(FunctionContext* ctx, ConstAggDataPtr __restrict state, Column* to) const override {
        auto& state_impl = this->data(const_cast<AggDataPtr>(state));
        // should check overflow before append, otherwise will generate invalid result.
        if (UNLIKELY(state_impl.check_overflow(ctx))) {
            return;
        }

        auto* column = down_cast<ArrayColumn*>(to);
        column->append_array_element(*(state_impl.get_data_column()), state_impl.null_count);

        // should check overflow after append, otherwise the result column with multi row will be overflow.
        if (UNLIKELY(state_impl.check_overflow(*to, ctx))) {
            return;
        }
    }

    void finalize_to_column(FunctionContext* ctx, ConstAggDataPtr __restrict state, Column* to) const override {
        return serialize_to_column(ctx, state, to);
    }

    void convert_to_serialize_format(FunctionContext* ctx, const Columns& src, size_t chunk_size,
                                     MutableColumnPtr& dst) const override {
        auto* column = down_cast<ArrayColumn*>(dst.get());
        auto* offsets_col = column->offsets_column_raw_ptr();
        auto* elements_column = column->elements_column_raw_ptr();

        for (size_t i = 0; i < chunk_size; i++) {
            elements_column->append_datum(src[0]->get(i));
            offsets_col->append(offsets_col->immutable_data().back() + 1);
        }
    }

    void reset(FunctionContext* ctx, const Columns& args, AggDataPtr __restrict state) const override {
        this->data(state).reset();
    }

    void get_values(FunctionContext* ctx, ConstAggDataPtr __restrict state, Column* dst, size_t start,
                    size_t end) const override {
        auto& state_impl = this->data(const_cast<AggDataPtr>(state));
        const auto& data_column = state_impl.get_data_column();
        auto* array_column = down_cast<ArrayColumn*>(dst);
        for (auto i = start; i < end; i++) {
            array_column->append_array_element(*data_column, state_impl.null_count);
            if (UNLIKELY(state_impl.check_overflow(*array_column, ctx))) {
                return;
            }
        }
    }

    void update_batch_single_state_with_frame(FunctionContext* ctx, AggDataPtr __restrict state, const Column** columns,
                                              int64_t peer_group_start, int64_t peer_group_end, int64_t frame_start,
                                              int64_t frame_end) const override {
        // For distinct mode, data_column used as a result cache for get_values method, any updates to
        // this state should invalidate the cache.
        this->data(state).data_column.resize(0);
        const auto* column = down_cast<const InputColumnType*>(columns[0]);
        this->data(state).update(ctx->mem_pool(), *column, frame_start, frame_end - frame_start);
        this->data(state).check_overflow(ctx);
    }

    void update_single_state_null(FunctionContext* ctx, AggDataPtr __restrict state, int64_t peer_group_start,
                                  int64_t peer_group_end) const override {
        // For distinct mode, data_column used as a result cache for get_values method, any updates to
        // this state should invalidate the cache.
        this->data(state).data_column.resize(0);
        this->data(state).append_null(peer_group_end - peer_group_start);
    }

    std::string get_name() const override { return is_distinct ? "array_agg_distinct" : "array_agg"; }
};

template <LogicalType LT, bool is_distinct, typename MyHashSet = std::set<int>>
using ArrayAggAggregateFunction = ArrayAggAggregateFunctionBase<LT, is_distinct, ArrayAggAggregateState, MyHashSet>;

template <LogicalType LT, bool is_distinct, typename MyHashSet = std::set<int>>
using ArrayAggAggregateWindowFunction = ArrayAggAggregateFunctionBase<LT, is_distinct, ArrayAggWindowState, MyHashSet>;

// input columns result in intermediate result: struct{array[col0], array[col1], array[col2]... array[coln]}
// return ordered array[col0']
struct ArrayAggAggregateStateV2 {
    void initialize(FunctionContext* ctx) const {
        for (auto i = 0; i < ctx->get_arg_types().size(); ++i) {
            data_columns.emplace_back(ctx->create_column(*ctx->get_arg_type(i), true));
        }
        DCHECK(data_columns.size() == ctx->get_is_asc_order().size() + 1);
    }

    void update(const Column& column, size_t index, size_t offset, size_t count) {
        data_columns[index]->append(column, offset, count);
    }

    void update_nulls(size_t index, size_t count) { data_columns[index]->append_nulls(count); }

    bool check_overflow(FunctionContext* ctx) const {
        std::string err_msg;
        for (size_t i = 0; i < data_columns.size(); i++) {
            Status st = data_columns[i]->capacity_limit_reached();
            if (!st.ok()) {
                ctx->set_error(fmt::format("The column generated by array_agg is overflow: {}", st.message()).c_str());
                return true;
            }
        }
        return false;
    }

    static bool check_overflow(const Column& col, FunctionContext* ctx) {
        Status st = col.capacity_limit_reached();
        if (!st.ok()) {
            ctx->set_error(fmt::format("The column generated by array_agg is overflow: {}", st.message()).c_str());
            return true;
        }
        return false;
    }

    // release the trailing N-1 order-by columns
    void release_order_by_columns() {
        if (data_columns.empty()) {
            return;
        }
        for (auto i = 1; i < data_columns.size(); ++i) {
            data_columns[i].reset();
        }
        data_columns.resize(1);
    }

    void reset(FunctionContext* ctx) { data_columns.clear(); }

    // using pointer rather than vector to avoid variadic size
    // array_agg(a order by b, c, d), the a,b,c,d are put into data_columns in order.
    mutable MutableColumns data_columns;
};

struct ArrayAggWindowStateV2 : public ArrayAggAggregateStateV2 {
    using Base = ArrayAggAggregateStateV2;
    using Base::Base;
    using Base::initialize;
    using Base::reset;

    void initialize(FunctionContext* ctx) const {
        Base::initialize(ctx);
        result_column = ctx->create_column(ctx->get_return_type(), true);
    }
    void reset(FunctionContext* ctx) {
        Base::reset(ctx);
        result_column.reset();
        DCHECK(data_columns.empty() && result_column == nullptr);
        initialize(ctx);
    }
    mutable MutableColumnPtr result_column;
};

template <typename AggState>
class ArrayAggAggregateFunctionV2 final
        : public AggregateFunctionBatchHelper<AggState, ArrayAggAggregateFunctionV2<AggState>> {
public:
    void create(FunctionContext* ctx, AggDataPtr __restrict ptr) const override {
        auto* state = new (ptr) AggState;
        state->initialize(ctx);
    }

    void update(FunctionContext* ctx, const Column** columns, AggDataPtr __restrict state,
                size_t row_num) const override {
        for (auto i = 0; i < ctx->get_num_args(); ++i) {
            if (UNLIKELY(columns[i]->size() <= row_num)) {
                ctx->set_error(std::string(get_name() + "'s update row number overflow").c_str(), false);
                return;
            }
            // TODO: update is random access, so we could not pre-reserve memory for State, which is the bottleneck
            if ((columns[i]->is_nullable() && columns[i]->is_null(row_num)) || columns[i]->only_null()) {
                this->data(state).update_nulls(i, 1);
                continue;
            }
            auto* data_col = columns[i];
            auto tmp_row_num = row_num;
            if (columns[i]->is_constant()) {
                // just copy the first const value.
                data_col = down_cast<const ConstColumn*>(columns[i])->data_column().get();
                tmp_row_num = 0;
            }
            this->data(state).update(*data_col, i, tmp_row_num, 1);
        }
    }

    // struct and array elements aren't be null, as they consist from several columns
    void merge(FunctionContext* ctx, const Column* column, AggDataPtr __restrict state, size_t row_num) const override {
        const auto input_columns = down_cast<const StructColumn*>(ColumnHelper::get_data_column(column))->fields();
        for (auto i = 0; i < input_columns.size(); ++i) {
            auto array_column = down_cast<const ArrayColumn*>(ColumnHelper::get_data_column(input_columns[i].get()));
            const auto offsets = array_column->offsets().immutable_data();
            this->data(state).update(array_column->elements(), i, offsets[row_num],
                                     offsets[row_num + 1] - offsets[row_num]);
        }
    }

    // serialize each state->column to a [nullable] array in a [nullable] struct
    void serialize_to_column(FunctionContext* ctx, ConstAggDataPtr __restrict state, Column* to) const override {
        auto& state_impl = this->data(const_cast<AggDataPtr>(state));
        // should check overflow before append, otherwise will generate invalid result.
        if (UNLIKELY(state_impl.check_overflow(ctx))) {
            return;
        }

        auto* struct_column = down_cast<StructColumn*>(ColumnHelper::get_data_column(to));
        if (to->is_nullable()) {
            down_cast<NullableColumn*>(to)->null_column_data().emplace_back(0);
        }
        for (auto i = 0; i < struct_column->fields_size(); ++i) {
            auto elem_size = state_impl.data_columns[i]->size();

            auto* field_column = struct_column->field_column_raw_ptr(i);
            auto array_col = down_cast<ArrayColumn*>(ColumnHelper::get_data_column(field_column));
            if (field_column->is_nullable()) {
                down_cast<NullableColumn*>(field_column)->null_column_data().emplace_back(0);
            }
            auto* elements_col = array_col->elements_column_raw_ptr();
            auto* offsets_col = array_col->offsets_column_raw_ptr();
            if (state_impl.data_columns[i]->only_null()) {
                elements_col->append_nulls(elem_size);
            } else {
                elements_col->append(
                        *ColumnHelper::unpack_and_duplicate_const_column(elem_size, state_impl.data_columns[i]), 0,
                        elem_size);
            }
            offsets_col->append(offsets_col->immutable_data().back() + elem_size);
            state_impl.data_columns[i].reset();
        }
        state_impl.data_columns.clear();

        // should check overflow after append, otherwise the result column with multi row will be overflow.
        if (UNLIKELY(state_impl.check_overflow(*to, ctx))) {
            return;
        }
    }

    // finalize each state->column to a [nullable] array
    void finalize_to_column(FunctionContext* ctx, ConstAggDataPtr __restrict state, Column* to) const override {
        auto defer = DeferOp([&]() {
            if (ctx->has_error() && to != nullptr) {
                to->append_default();
            }
        });
        if (UNLIKELY(!ColumnHelper::get_data_column(to)->is_array())) {
            ctx->set_error(std::string("The output column of " + get_name() +
                                       " finalize_to_column() is not array, but is " + to->get_name())
                                   .c_str(),
                           false);
            return;
        }
        auto& state_impl = this->data(const_cast<AggDataPtr>(state));
        // should check overflow before append, otherwise will generate invalid result.
        if (UNLIKELY(state_impl.check_overflow(ctx))) {
            return;
        }
        auto& res = state_impl.data_columns[0];
        auto elem_size = state_impl.data_columns[0]->size();
        auto array_col = down_cast<ArrayColumn*>(ColumnHelper::get_data_column(to));
        if (to->is_nullable()) {
            down_cast<NullableColumn*>(to)->null_column_data().emplace_back(0);
        }
        DCHECK(!res->is_constant());
        Permutation perm;
        if (!ctx->get_is_asc_order().empty()) {
            Columns order_by_columns;
            SortDescs sort_desc(ctx->get_is_asc_order(), ctx->get_nulls_first());
            order_by_columns.assign(state_impl.data_columns.begin() + 1, state_impl.data_columns.end());
            Status st = sort_and_tie_columns(ctx->state()->cancelled_ref(), order_by_columns, sort_desc, &perm);
            // release order-by columns early
            order_by_columns.clear();
            // for window function, we can not clear State::data_columns, since its data are used to produce
            // result,for an example: array_agg(c) over(partition by a order by b)
            if constexpr (!std::is_same_v<AggState, ArrayAggWindowStateV2>) {
                state_impl.release_order_by_columns();
            }
            if (UNLIKELY(ctx->state()->cancelled_ref())) {
                ctx->set_error("array_agg detects cancelled.", false);
                return;
            }
            if (UNLIKELY(!st.ok())) {
                ctx->set_error(st.to_string().c_str(), false);
                return;
            }
        }
        // further remove duplicated values
        // TODO(fzh) optimize N*N, since distinct is often rewritten to group by, the distinct values are not too many.
        Buffer<bool> duplicated_flags;
        if (ctx->get_is_distinct()) {
            duplicated_flags.resize(elem_size);
            bool is_duplicated = false;
            phmap::flat_hash_set<uint32_t> sets;
            std::vector<uint32_t> hash(elem_size, 0);
            res->fnv_hash(hash.data(), 0, elem_size);
            for (auto row_id = 0; row_id < elem_size; row_id++) {
                is_duplicated = false;
                if (!sets.contains(hash[row_id])) {
                    sets.emplace(hash[row_id]);
                } else {
                    for (auto next_id = 0; next_id < row_id; next_id++) {
                        if (hash[row_id] == hash[next_id] && res->equals(next_id, *res, row_id)) {
                            is_duplicated = true;
                            break;
                        }
                    }
                }
                duplicated_flags[row_id] = is_duplicated;
            }
        }
        Buffer<uint32_t> index;
        if (!duplicated_flags.empty() || !perm.empty()) {
            auto res_num = 0;
            index.resize(elem_size);
            for (auto row_id = 0; row_id < elem_size; row_id++) {
                if (duplicated_flags.empty()) {
                    index[res_num++] = perm[row_id].index_in_chunk;
                } else {
                    if (perm.empty()) {
                        if (!duplicated_flags[row_id]) {
                            index[res_num++] = row_id;
                        }
                    } else {
                        if (!duplicated_flags[perm[row_id].index_in_chunk]) {
                            index[res_num++] = perm[row_id].index_in_chunk;
                        }
                    }
                }
            }
            index.resize(res_num);
            elem_size = res_num;
        }
        auto* elements_col = array_col->elements_column_raw_ptr();
        if (index.empty()) {
            elements_col->append(*res, 0, elem_size);
        } else {
            elements_col->append_selective(*res, index);
        }
        // for window function, we can not clear State::data_columns, since its data are used to produce
        // result,for an example: array_agg(c) over(partition by a order by b)
        if constexpr (!std::is_same_v<AggState, ArrayAggWindowStateV2>) {
            state_impl.data_columns.clear(); // early release memory
        }
        auto* offsets_col = array_col->offsets_column_raw_ptr();
        offsets_col->append(offsets_col->immutable_data().back() + elem_size);
        // should check overflow after append, otherwise the result column with multi row will be overflow.
        if (UNLIKELY(state_impl.check_overflow(*to, ctx))) {
            return;
        }
    }

    // convert each cell of a row to a [nullable] array in a struct
    void convert_to_serialize_format(FunctionContext* ctx, const Columns& src, size_t chunk_size,
                                     MutableColumnPtr& dst) const override {
        auto* struct_column = down_cast<StructColumn*>(ColumnHelper::get_data_column(dst.get()));
        if (dst->is_nullable()) {
            for (size_t i = 0; i < chunk_size; i++) {
                down_cast<NullableColumn*>(dst.get())->null_column_data().emplace_back(0);
            }
        }
        for (auto j = 0; j < struct_column->fields_size(); ++j) {
            auto* field_column = struct_column->field_column_raw_ptr(j);
            auto array_col = down_cast<ArrayColumn*>(ColumnHelper::get_data_column(field_column));
            if (field_column->is_nullable()) {
                for (size_t i = 0; i < chunk_size; i++) {
                    down_cast<NullableColumn*>(field_column)->null_column_data().emplace_back(0);
                }
            }
            auto* element_column = array_col->elements_column_raw_ptr();
            auto* offsets_col = array_col->offsets_column_raw_ptr();
            for (size_t i = 0; i < chunk_size; i++) {
                element_column->append_datum(src[j]->get(i));
                offsets_col->append(offsets_col->immutable_data().back() + 1);
            }
        }
    }

    void reset(FunctionContext* ctx, const Columns& args, AggDataPtr __restrict state) const override {
        this->data(state).reset(ctx);
    }

    void get_values(FunctionContext* ctx, ConstAggDataPtr __restrict state, Column* dst, size_t start,
                    size_t end) const override {
        if constexpr (std::is_same_v<AggState, ArrayAggWindowStateV2>) {
            auto& state_impl = this->data(const_cast<AggDataPtr>(state));
            auto* result_column = state_impl.result_column.get();
            if (result_column->size() == 0) {
                finalize_to_column(ctx, state, result_column);
            }
            DCHECK(result_column->size() == 1);
            dst->append_value_multiple_times(*result_column, 0, end - start);
        }
    }

    void update_batch_single_state_with_frame(FunctionContext* ctx, AggDataPtr __restrict state, const Column** columns,
                                              int64_t peer_group_start, int64_t peer_group_end, int64_t frame_start,
                                              int64_t frame_end) const override {
        if constexpr (std::is_same_v<AggState, ArrayAggWindowStateV2>) {
            this->data(state).result_column->resize(0);
        }

        for (auto i = frame_start; i < frame_end; ++i) {
            update(ctx, columns, state, i);
        }
    }

    // V2 support order by
    std::string get_name() const override { return "array_agg2"; }
};
} // namespace starrocks
