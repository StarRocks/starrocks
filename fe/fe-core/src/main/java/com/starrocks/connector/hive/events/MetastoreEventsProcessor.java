// This file is licensed under the Elastic License 2.0. Copyright 2021-present, StarRocks Inc.

package com.starrocks.connector.hive.events;

import com.google.common.collect.Lists;
import com.google.common.collect.Maps;
import com.starrocks.common.Config;
import com.starrocks.common.ThreadPoolManager;
import com.starrocks.common.util.LeaderDaemon;
import com.starrocks.connector.hive.CacheUpdateProcessor;
import org.apache.hadoop.hive.metastore.IMetaStoreClient;
import org.apache.hadoop.hive.metastore.api.NotificationEvent;
import org.apache.hadoop.hive.metastore.api.NotificationEventResponse;
import org.apache.hadoop.hive.metastore.messaging.MessageDeserializer;
import org.apache.hadoop.hive.metastore.messaging.json.JSONMessageDeserializer;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Future;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;
import javax.annotation.Nullable;

/**
 * A metastore event is a instance of the class
 * {@link NotificationEvent}. Metastore can be
 * configured, to work with Listeners which are called on various DDL operations like
 * create/alter/drop operations on database, table, partition etc. Each event has a unique
 * incremental id and the generated events are be fetched from Metastore to get
 * incremental updates to the metadata stored in Hive metastore using the the public API
 * <code>get_next_notification</code> These events could be generated by external
 * Metastore clients like Apache Hive or Apache Spark configured to talk with the same metastore.
 * <p>
 * This class is used to poll metastore for such events at a given frequency. By observing
 * such events, we can take appropriate action on the {@link com.starrocks.connector.hive.CachingHiveMetastore}
 * (refresh/invalidate/add/remove) so that represents the latest information
 * available in metastore. We keep track of the last synced event id in each polling
 * iteration so the next batch can be requested appropriately. The current batch size is
 * constant and set to {@link Config#hms_events_batch_size_per_rpc}.
 */
public class MetastoreEventsProcessor extends LeaderDaemon {
    private static final Logger LOG = LogManager.getLogger(MetastoreEventsProcessor.class);
    public static final String HMS_ADD_THRIFT_OBJECTS_IN_EVENTS_CONFIG_KEY =
            "hive.metastore.notifications.add.thrift.objects";

    // for deserializing from JSON strings from metastore event
    private static final MessageDeserializer MESSAGE_DESERIALIZER = new JSONMessageDeserializer();

    // thread pool for processing the metastore events
    private final ExecutorService eventsProcessExecutor =
            ThreadPoolManager.newDaemonFixedThreadPool(Config.hms_process_events_parallel_num,
                    Integer.MAX_VALUE, "hms-event-processor-executor", true);

    // event factory which is used to get or create MetastoreEvents
    private final MetastoreEventFactory metastoreEventFactory;

    private Map<String, CacheUpdateProcessor> cacheUpdateProcessors = Maps.newHashMap();

    // Locking is required during event processing that avoiding data inconsistency
    // when manually executing refresh operation. This lock needs to be acquired
    // when executing refresh table or refresh partition in HiveMetaCache
    private final ReadWriteLock eventProcessorLock = new ReentrantReadWriteLock();

    // resourcemapcatalog.dbName.tableName
    private final List<String> tables = Lists.newArrayList();

    private final ReadWriteLock tablesLock = new ReentrantReadWriteLock();

    HiveExternalTableCounter counter = new HiveExternalTableCounter();

    public MetastoreEventsProcessor() {
        super(MetastoreEventsProcessor.class.getName(), Config.hms_events_polling_interval_ms);
        this.metastoreEventFactory = new MetastoreEventFactory();
    }

    public void registerCatalogCache(String catalogName, CacheUpdateProcessor cache) {
        cacheUpdateProcessors.put(catalogName, cache);
    }

    public void unRegisterCatalogCache(String catalogName) {
        cacheUpdateProcessors.remove(catalogName);
    }

    public void registerTable(String catalogTableName) {
        tablesLock.writeLock().lock();
        try {
            tables.add(catalogTableName);
            LOG.info("Succeed to register {} to Metastore event processor", catalogTableName);
        } finally {
            tablesLock.writeLock().unlock();
        }
    }

    public void unregisterTable(String catalogTableName) {
        tablesLock.writeLock().lock();
        try {
            tables.remove(catalogTableName);
            LOG.info("Succeed to remove {} from Metastore event processor", catalogTableName);
        } finally {
            tablesLock.writeLock().unlock();
        }
    }

    public boolean containsHiveTable(String catalogTableName) {
        tablesLock.readLock().lock();
        try {
            return tables.contains(catalogTableName);
        } finally {
            tablesLock.readLock().unlock();
        }
    }

    /**
     * Gets metastore notification events from the given eventId. The returned list of
     * NotificationEvents are filtered using the NotificationFilter provided if it is not null.
     *
     * @param catalogName The catalog name of current hive metastore instance.
     * @param getAllEvents If this is true all the events since eventId are returned.
     *                     Note that Hive MetaStore can limit the response to a specific
     *                     maximum number of limit based on the value of configuration
     *                     {@code hive.metastore.max.event.response}.
     *                     If it is false, only {@link Config#hms_events_batch_size_per_rpc} events are
     *                     returned, caller is expected to issue more calls to this method
     *                     to fetch the remaining events.
     * @param filter       This is a nullable argument. If not null, the events are filtered
     *                     and then returned using this. Otherwise, all the events are returned.
     * @return List of NotificationEvents from metastore since eventId.
     * @throws MetastoreNotificationFetchException In case of exceptions from HMS.
     */
    private List<NotificationEvent> getNextHMSEvents(String catalogName,
                                                     final boolean getAllEvents,
                                                     @Nullable final IMetaStoreClient.NotificationFilter filter) {
        LOG.info("Start to pull events on catalog [{}]", catalogName);
        CacheUpdateProcessor updateProcessor = cacheUpdateProcessors.get(catalogName);
        if (updateProcessor == null) {
            LOG.error("Failed to get cacheUpdateProcessor by catalog {}.", catalogName);
            return Collections.emptyList();
        }

        NotificationEventResponse response = updateProcessor.getNextEventResponse(catalogName, getAllEvents);
        if (response == null) {
            return Collections.emptyList();
        }

        if (filter == null) {
            return response.getEvents();
        }

        List<NotificationEvent> filteredEvents = new ArrayList<>();
        for (NotificationEvent event : response.getEvents()) {
            if (filter.accept(event)) {
                filteredEvents.add(event);
            }
        }

        return filteredEvents;
    }

    /**
     * Fetch the next batch of NotificationEvents from metastore. The default batch size is
     * <code>{@link Config#hms_events_batch_size_per_rpc}</code>
     */
    private List<NotificationEvent> getNextHMSEvents(String catalogName)
            throws MetastoreNotificationFetchException {
        return getNextHMSEvents(catalogName, false, null);
    }

    private void doExecuteWithPartialProgress(List<MetastoreEvent> events) {
        List<Future<?>> futures = Lists.newArrayList();
        events.forEach(event -> {
            futures.add(eventsProcessExecutor.submit(event::process));
        });

        for (Future<?> future : futures) {
            try {
                future.get();
            } catch (Exception e) {
                throw new MetastoreNotificationException(e);
            }
        }
    }

    private void doExecute(List<MetastoreEvent> events, CacheUpdateProcessor cacheProcessor) {
        for (MetastoreEvent event : events) {
            try {
                event.process();
            } catch (Exception e) {
                if (event instanceof BatchEvent) {
                    cacheProcessor.setLastSyncedEventId(((BatchEvent<?>) event).getFirstEventId() - 1);
                } else {
                    cacheProcessor.setLastSyncedEventId(event.getEventId() - 1);
                }
                throw e;
            }
        }
    }

    /**
     * Process the given list of notification events. Useful for tests which provide a list of events
     */
    private void processEvents(List<NotificationEvent> events, String catalogName) {
        CacheUpdateProcessor cacheProcessor = cacheUpdateProcessors.get(catalogName);
        List<MetastoreEvent> filteredEvents = metastoreEventFactory.getFilteredEvents(events, cacheProcessor, catalogName);

        if (filteredEvents.isEmpty()) {
            cacheProcessor.setLastSyncedEventId(events.get(events.size() - 1).getEventId());
            return;
        }

        LOG.info("Notification events {} to be processed on catalog [{}]", events, catalogName);

        if (Config.enable_hms_parallel_process_evens) {
            doExecuteWithPartialProgress(filteredEvents);
        } else {
            doExecute(filteredEvents, cacheProcessor);
        }
        cacheProcessor.setLastSyncedEventId(filteredEvents.get(filteredEvents.size() - 1).getEventId());
    }

    @Override
    protected void runAfterCatalogReady() {
        List<String> catalogs = Lists.newArrayList(cacheUpdateProcessors.keySet());
        LOG.info("Start to pull [{}] events", catalogs);
        for (String catalogName : catalogs) {
            eventProcessorLock.writeLock().lock();
            List<NotificationEvent> events = Collections.emptyList();
            try {
                events = getNextHMSEvents(catalogName);
                if (!events.isEmpty()) {
                    LOG.info("Events size are {} on catalog [{}]", events.size(), catalogName);
                    processEvents(events, catalogName);
                }
            } catch (MetastoreNotificationFetchException e) {
                LOG.error("Failed to fetch hms events on {}. msg: ", catalogName, e);
            } catch (Exception ex) {
                LOG.error("Failed to process hive metastore [{}] events " +
                                "in the range of event id from {} to {}.", catalogName,
                        events.get(0).getEventId(), events.get(events.size() - 1).getEventId(), ex);
            } finally {
                eventProcessorLock.writeLock().unlock();
            }
        }
    }

    public static class TableName {
        private final String dbName;
        private final String tblName;

        public TableName(String dbName, String tblName) {
            this.dbName = dbName;
            this.tblName = tblName;
        }

        public String getDbName() {
            return dbName;
        }

        public String getTblName() {
            return tblName;
        }

        @Override
        public boolean equals(Object o) {
            if (this == o) {
                return true;
            }
            if (o == null || getClass() != o.getClass()) {
                return false;
            }
            TableName tableName = (TableName) o;
            return Objects.equals(dbName, tableName.dbName) && Objects.equals(tblName, tableName.tblName);
        }

        @Override
        public int hashCode() {
            return Objects.hash(dbName, tblName);
        }
    }

    public static MessageDeserializer getMessageDeserializer() {
        return MESSAGE_DESERIALIZER;
    }

    public HiveExternalTableCounter getCounter() {
        return counter;
    }

    public ReadWriteLock getEventProcessorLock() {
        return eventProcessorLock;
    }

    public static class HiveExternalTableCounter {
        // Each hive table corresponds to the number counter of the StarRocks hive external table
        private final ConcurrentHashMap<HiveExternalTableIdentifier, Integer> hiveTblCounter = new ConcurrentHashMap<>();

        public int add(String catalog, String database, String table) {
            HiveExternalTableIdentifier identifier = HiveExternalTableIdentifier.of(catalog, database, table);
            return hiveTblCounter.compute(identifier, (k, v) -> v == null ? 1 : v + 1);
        }

        public int reduce(String catalog, String database, String table) {
            HiveExternalTableIdentifier identifier = HiveExternalTableIdentifier.of(catalog, database, table);
            return hiveTblCounter.compute(identifier, (k, v) -> v == null || v == 0 ? 0 : v - 1);
        }

        public int get(String catalog, String database, String table) {
            HiveExternalTableIdentifier identifier = HiveExternalTableIdentifier.of(catalog, database, table);
            return hiveTblCounter.getOrDefault(identifier, 0);
        }

        private static class HiveExternalTableIdentifier {
            String catalogName;
            String databaseName;
            String tableName;

            private HiveExternalTableIdentifier(String catalogName, String databaseName, String tableName) {
                this.catalogName = catalogName;
                this.databaseName = databaseName;
                this.tableName = tableName;
            }

            public static HiveExternalTableIdentifier of(String catalogName, String databaseName, String tableName) {
                return new HiveExternalTableIdentifier(catalogName, databaseName, tableName);
            }

            @Override
            public boolean equals(Object o) {
                if (this == o) {
                    return true;
                }
                if (o == null || getClass() != o.getClass()) {
                    return false;
                }

                HiveExternalTableIdentifier that = (HiveExternalTableIdentifier) o;

                return Objects.equals(catalogName, that.catalogName) &&
                        Objects.equals(databaseName, that.databaseName) &&
                        Objects.equals(tableName, that.tableName);
            }

            @Override
            public int hashCode() {
                return Objects.hash(catalogName, databaseName, tableName);
            }
        }
    }

    public boolean isCachedCatalog(String catalogName) {
        return cacheUpdateProcessors.keySet().contains(catalogName);
    }
}
