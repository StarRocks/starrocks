-- name: test_event_scheduler
set enable_pipeline_event_scheduler=true;
set enable_group_execution=false;
set enable_per_bucket_optimize=false;

-- basic scan test:
CREATE TABLE `t0` (
  `c0` int DEFAULT NULL,
  `c1` bigint DEFAULT NULL,
  `c2` string DEFAULT NULL
) ENGINE=OLAP
DUPLICATE KEY(`c0`)
COMMENT "OLAP"
DISTRIBUTED BY HASH(`c0`) BUCKETS 1
PROPERTIES (
"replication_num" = "1"
);
-- 
set pipeline_dop = 1;
set io_tasks_per_scan_operator=1;

insert into t0 SELECT generate_series, generate_series, generate_series FROM TABLE(generate_series(1,  4));
select * from t0;
insert into t0 SELECT generate_series, generate_series, generate_series FROM TABLE(generate_series(1,  409600));
-- scan has output always false
select c0 from t0 where c0 is null;

-- simple agg without local-exchange once stage agg
select count(c1) from t0;

-- multi-scan tasks
CREATE TABLE `t1` (
  `c0` int DEFAULT NULL,
  `c1` bigint DEFAULT NULL,
  `c2` string DEFAULT NULL
) ENGINE=OLAP
DUPLICATE KEY(`c0`)
COMMENT "OLAP"
DISTRIBUTED BY HASH(`c0`) BUCKETS 4
PROPERTIES (
"replication_num" = "1"
);
set io_tasks_per_scan_operator=4;
insert into t1 SELECT generate_series, generate_series, generate_series FROM TABLE(generate_series(1,  409600));
-- simple with local-exchange, two stage block agg
select count(c1) from t1;
-- simple with local-exchange, two stage streaming distinct agg
insert into blackhole() select distinct c1,c2,c0 from t1;
-- simple with local-exchange, two stage streaming agg
insert into blackhole() select c2,sum(c0),c1 from t1 group by c1,c2;

set pipeline_dop=2;
-- test with shared morsel queue
select count(c1) from t1;

-- test exchange with limit
select count(*) from (select * from t1 limit 1000) t;

-- test with force streaming
set streaming_preaggregation_mode="force_streaming";
insert into blackhole() select distinct c1,c2,c0 from t1;

-- test with force streaming
set streaming_preaggregation_mode="force_streaming";
insert into blackhole() select sum(c0),c1,c2 from t1 group by c1, c2;
